{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_model='/home/nada.saadi/CTPET/hecktor2022_cropped/mda-ctonly-PT/ctonly-PT-with4.pth'\n",
    "pet_model='/home/nada.saadi/CTPET/hecktor2022_cropped/mda-ptonly-PT/ptonly-PT-with4.pth'\n",
    "\n",
    "# ct_model_6='/home/nada.saadi/CTPET/hecktor2022_cropped/6thctonlychannel_PRET/6thCTonly_channel_pret.pth'\n",
    "# pet_model_6='/home/nada.saadi/CTPET/hecktor2022_cropped/6th_PET_channel_PRET/6thPETonly_channel_pret.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "# import wandb\n",
    "\n",
    "import monai\n",
    "from monai.losses import DiceCELoss, DiceFocalLoss, FocalLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    MapTransform,\n",
    "    ScaleIntensityd,\n",
    "    #AddChanneld,\n",
    "    SpatialPadd,\n",
    "    CenterSpatialCropd,\n",
    "    EnsureChannelFirstd,\n",
    "    ConcatItemsd,\n",
    "    AdjustContrastd, \n",
    "    Rand3DElasticd,\n",
    "    HistogramNormalized,\n",
    "    NormalizeIntensityd,\n",
    "    Invertd,\n",
    "    SaveImage,\n",
    "\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SwinUNETR, UNETR, SegResNet\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai import data\n",
    "\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "\n",
    "from monai.transforms import apply_transform\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nada.saadi/miniconda3/envs/clam/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.unetr UNETR.__init__:pos_embed: Argument `pos_embed` has been deprecated since version 1.2. It will be removed in version 1.4. please use `proj_type` instead.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the pretrained weights\n",
    "#pretrained_weights = torch.load('/home/nada.saadi/CTPET/hecktor2022_cropped/4centers-ctonly/4centers-ctonly.pth')\n",
    "\n",
    "\n",
    "model_ct = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072, \n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "model_pet = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072, \n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNETR(\n",
       "  (vit): ViT(\n",
       "    (patch_embedding): PatchEmbeddingBlock(\n",
       "      (patch_embeddings): Sequential(\n",
       "        (0): Rearrange('b c (h p1) (w p2) (d p3) -> b (h w d) (p1 p2 p3 c)', p1=16, p2=16, p3=16)\n",
       "        (1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x TransformerBlock(\n",
       "        (mlp): MLPBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (fn): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SABlock(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (proj_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (proj_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (input_rearrange): Rearrange('b h (l d) -> b l h d', l=12)\n",
       "          (out_rearrange): Rearrange('b h l d -> b l (h d)')\n",
       "          (drop_output): Dropout(p=0.0, inplace=False)\n",
       "          (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(64, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList()\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(16, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ct.load_state_dict(torch.load(ct_model))\n",
    "model_pet.load_state_dict(torch.load(pet_model))\n",
    "\n",
    "model_ct.eval() \n",
    "model_pet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_data='/home/nada.saadi/CTPET/hecktor2022_cropped/test_ct_only_mda.json'\n",
    "pet_data='/home/nada.saadi/CTPET/hecktor2022_cropped/test_pet_only_mda.json'\n",
    "\n",
    "# ct_data_6='/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_train_new.json'\n",
    "# pet_data_6='/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_PET_train_new.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified JSON file has been saved to /home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedct_json_file.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the existing JSON file\n",
    "original_json_path = ct_data\n",
    "# Path for the new simplified JSON file\n",
    "new_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedct_json_file.json'\n",
    "\n",
    "# Read the original JSON file\n",
    "with open(original_json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Modify each dictionary in the list to retain only 'ct' and 'seg' keys\n",
    "simplified_data = [{'ct': item['ct'], 'seg': item['seg']} for item in data if 'ct' in item and 'seg' in item]\n",
    "\n",
    "# Save the modified list of dictionaries to a new JSON file\n",
    "with open(new_json_path, 'w') as file:\n",
    "    json.dump(simplified_data, file, indent=4)\n",
    "\n",
    "print(f\"Simplified JSON file has been saved to {new_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_test_new.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m new_json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_ct_test_data_simplified_json_file.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Read the original JSON file\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moriginal_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     10\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Modify each dictionary in the list to retain only 'ct' and 'seg' keys\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_test_new.json'"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # Path to the existing JSON file\n",
    "# original_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_test_new.json'\n",
    "# # Path for the new simplified JSON file\n",
    "# new_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_ct_test_data_simplified_json_file.json'\n",
    "\n",
    "# # Read the original JSON file\n",
    "# with open(original_json_path, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Modify each dictionary in the list to retain only 'ct' and 'seg' keys\n",
    "# simplified_data = [{'pt': item['pt'], 'seg': item['seg']} for item in data if 'pt' in item and 'seg' in item]\n",
    "\n",
    "# # Save the modified list of dictionaries to a new JSON file\n",
    "# with open(new_json_path, 'w') as file:\n",
    "#     json.dump(simplified_data, file, indent=4)\n",
    "\n",
    "# print(f\"Simplified JSON file has been saved to {new_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test JSON file has been saved to /home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_pet_test.json\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # Path to the train JSON file\n",
    "# #train_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_train_new.json'\n",
    "# train_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_PET_train_new.json'\n",
    "# # Path for the new test JSON file\n",
    "# test_json_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_pet_test.json'\n",
    "\n",
    "# # Read the train JSON file\n",
    "# with open(train_json_path, 'r') as file:\n",
    "#     train_data = json.load(file)\n",
    "\n",
    "# # Filter the train data to get only the test files\n",
    "# test_data = [item for item in train_data if 'validation' in item and item['validation']]\n",
    "\n",
    "# # Save the test data to a new JSON file\n",
    "# with open(test_json_path, 'w') as file:\n",
    "#     json.dump(test_data, file, indent=4)\n",
    "\n",
    "# print(f\"Test JSON file has been saved to {test_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_test_data_6='/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_CT_test_new.json'\n",
    "# pet_test_data_6='/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_pet_test_new.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_data_used_simplified='/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedct_json_file.json'\n",
    "pet_data_used_simplified='/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedpt_json_file.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Open the JSON file\n",
    "# with open('/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedpt_json_file.json') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Print the first element\n",
    "# print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_data_format(data):\n",
    "#     if not isinstance(data, list):\n",
    "#         print(\"Data is not a list.\")\n",
    "#         return False\n",
    "\n",
    "#     for i, item in enumerate(data):\n",
    "#         if not isinstance(item, dict):\n",
    "#             print(f\"Item at index {i} is not a dictionary.\")\n",
    "#             return False\n",
    "#         if len(item) != 2:\n",
    "#             print(f\"Dictionary at index {i} does not have exactly two key-value pairs.\")\n",
    "#             return False\n",
    "\n",
    "#     print(\"Data format is correct.\")\n",
    "#     return True\n",
    "\n",
    "# # Check the format of valid_data\n",
    "# check_data_format(ct_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_modified_data(ct_data):\n",
    "#     modified_data = []\n",
    "#     for item in ct_data:\n",
    "#         modified_item = {key: item[key] for key in item.keys()}\n",
    "#         modified_data.append(modified_item)\n",
    "#     return modified_data\n",
    "\n",
    "# # Create a modified version of valid_data\n",
    "# modified_valid_data = create_modified_data(new_json_path)\n",
    "\n",
    "# # Check the format of modified_valid_data\n",
    "# check_data_format(modified_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipCT(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on hecktor classes:\n",
    "    label 1 is the tumor\n",
    "    label 2 is the lymph node\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            if key == \"ct\":\n",
    "                d[key] = torch.clip(d[key], min=-200, max=200)\n",
    "            # elif key == \"pt\":\n",
    "            #     d[key] = torch.clip(d[key], d[key].min(), 5)\n",
    "        return d\n",
    "\n",
    "class MulPTFM(MapTransform):\n",
    "    \"\"\"\n",
    "    Mult PT and FM \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "\n",
    "        fm = d[\"ct\"] > 0\n",
    "        d[\"pt\"] = d[\"pt\"] * fm\n",
    "        return d\n",
    "\n",
    "class SelectClass(MapTransform):\n",
    "    \"\"\"\n",
    "    Select the class for which you want to fine tune the model \n",
    "\n",
    "    \"\"\"\n",
    "    # def __init__(self, keys, cls=1):\n",
    "    #     super(self).__init__(keys)\n",
    "    #     self.cls = cls\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        d[\"seg\"][d[\"seg\"] == 1] = 0\n",
    "        # d[\"seg\"][d[\"seg\"] == 2] = 1\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms_ct = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\",  \"seg\"], ensure_channel_first = True),\n",
    "        SpatialPadd(keys=[\"ct\",  \"seg\"], spatial_size=(200, 200, 310), method='end'),\n",
    "        Orientationd(keys=[\"ct\",  \"seg\"], axcodes=\"PLS\"),\n",
    "        #NormalizeIntensityd(keys=[\"pt\"]),\n",
    "        ClipCT(keys=[\"ct\"]),\n",
    "        ScaleIntensityd(keys=[\"ct\",], minv=0, maxv=1),\n",
    "        #MulPTFM(keys=[\"ct\",\"pt\"]),\n",
    "        ConcatItemsd(keys=[ \"ct\"], name=\"ct\"),\n",
    "    ]\n",
    ")\n",
    "def create_dataloader(data, transforms, batch_size=2, shuffle=True):\n",
    "    # Create CacheDataset with the reformatted data\n",
    "    dataset = Dataset(data=data, transform=transforms)\n",
    "\n",
    "    # Create DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "val_loader = create_dataloader(ct_data, val_transforms_ct, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_gt.nii.gz'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedct_json_file.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    ct_test_data = json.load(file)\n",
    "\n",
    "# Access the data from the JSON file\n",
    "# Example: Print the first element\n",
    "print(ct_test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mjson_dir\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39mDataLoader(\n\u001b[1;32m      7\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mtest_data_ct, transform\u001b[38;5;241m=\u001b[39mval_transforms_ctpt),\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Batch size for testing can be 1 since no backpropagation is required\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with open(json_dir, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_loader =DataLoader(\n",
    "    dataset=Dataset(data=test_data_ct, transform=val_transforms_ctpt),\n",
    "    batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:27<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at: /home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_test_output_ct_saved.pt\n",
      "Testing - Avg Dice: 0.4338, Tumor Dice: 0.3914, Lymph Dice: 0.4983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4337661862373352, 0.3913649022579193, 0.49833863973617554)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import io\n",
    "\n",
    "# with open(json_dir, 'r') as f:\n",
    "#     test_data = json.load(f)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=Dataset(data=ct_test_data, transform=val_transforms_ct),\n",
    "    batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model_ct.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=3)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=3)\n",
    "\n",
    "# Dice metric for evaluation\n",
    "dice_metric_fn = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "dice_metric_batch_fn = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "\n",
    "pt_weights='/home/nada.saadi/CTPET/hecktor2022_cropped/mda-ctonly-PT/ctonly-PT-with4.pth'\n",
    "model_ct.load_state_dict(torch.load(pt_weights))\n",
    "def testing():\n",
    "    model_ct.eval()\n",
    "    dice_metric_fn.reset()\n",
    "    dice_metric_batch_fn.reset()\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(test_loader):\n",
    "            test_inputs, test_labels = batch_data[\"ct\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "            \n",
    "            test_outputs_ct = sliding_window_inference(test_inputs, (96, 96, 96), 4, model_ct)\n",
    "            \n",
    "            # Convert outputs and labels to one-hot format for DiceMetric calculation\n",
    "            test_outputs_ct = [AsDiscrete(argmax=True, to_onehot=3)(i) for i in decollate_batch(test_outputs_ct)]\n",
    "            test_labels = [AsDiscrete(to_onehot=3)(i) for i in decollate_batch(test_labels)]\n",
    "\n",
    "            dice_metric_fn(y_pred=test_outputs_ct, y=test_labels)\n",
    "            dice_metric_batch_fn(y_pred=test_outputs_ct, y=test_labels)\n",
    "            \n",
    "        # After processing all batches, save the outputs\n",
    "    #ct_save_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/test_output_ct_saved.pt'\n",
    "    ct_save_path_6thcenter = '/home/nada.saadi/CTPET/hecktor2022_cropped/HGJ_test_output_ct_saved.pt'\n",
    "    torch.save(test_outputs_ct, ct_save_path_6thcenter)\n",
    "    print(f\"Outputs saved at: {ct_save_path_6thcenter}\")\n",
    "    \n",
    "\n",
    "    mean_dice_test = dice_metric_fn.aggregate().item()\n",
    "    metric_batch_test = dice_metric_batch_fn.aggregate()\n",
    "    metric_tumor = metric_batch_test[0].item()\n",
    "    metric_lymph = metric_batch_test[1].item()\n",
    "\n",
    "    print(f\"Testing - Avg Dice: {mean_dice_test:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "    return mean_dice_test, metric_tumor, metric_lymph\n",
    "    # Save the weights\n",
    "testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005/MDA-005_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005/MDA-005_gt.nii.gz'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/simplifiedpt_json_file.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    pt_test_data = json.load(file)\n",
    "\n",
    "# Access the data from the JSON file\n",
    "# Example: Print the first element\n",
    "print(pt_test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms_pt = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[ \"pt\", \"seg\"], ensure_channel_first = True),\n",
    "        SpatialPadd(keys=[ \"pt\", \"seg\"], spatial_size=(200, 200, 310), method='end'),\n",
    "        Orientationd(keys=[ \"pt\", \"seg\"], axcodes=\"PLS\"),\n",
    "        NormalizeIntensityd(keys=[\"pt\"]),\n",
    "        ClipCT(keys=[\"pt\"]),\n",
    "        ScaleIntensityd(keys=[\"pt\"], minv=0, maxv=1),\n",
    "        #MulPTFM(keys=[\"ct\",\"pt\"]),\n",
    "        ConcatItemsd(keys=[\"pt\"], name=\"pt\"),\n",
    "    ]\n",
    ")\n",
    "def create_dataloader(data, transforms, batch_size=2, shuffle=True):\n",
    "    # Create CacheDataset with the reformatted data\n",
    "    dataset = Dataset(data=data, transform=transforms)\n",
    "\n",
    "    # Create DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "val_loader = create_dataloader(pt_test_data, val_transforms_pt, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:22<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at: /home/nada.saadi/CTPET/hecktor2022_cropped/test_outputs_pt_saved.pt\n",
      "Testing - Avg Dice: 0.6573, Tumor Dice: 0.6898, Lymph Dice: 0.6491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6572763919830322, 0.6897528767585754, 0.6490647196769714)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=Dataset(data=pt_test_data, transform=val_transforms_pt),\n",
    "    batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model_pet.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=3)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=3)\n",
    "\n",
    "# Dice metric for evaluation\n",
    "dice_metric_fn = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "dice_metric_batch_fn = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "\n",
    "# pt_weights='/home/nada.saadi/CTPET/hecktor2022_cropped/4centers-ctonly/4centers-ctonly.pth'\n",
    "# model_ct.load_state_dict(torch.load(pt_weights))\n",
    "def testing():\n",
    "    model_ct.eval()\n",
    "    dice_metric_fn.reset()\n",
    "    dice_metric_batch_fn.reset()\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(test_loader):\n",
    "            test_inputs, test_labels = batch_data[\"pt\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "            \n",
    "            test_outputs_pt = sliding_window_inference(test_inputs, (96, 96, 96), 4, model_pet)\n",
    "            \n",
    "            # Convert outputs and labels to one-hot format for DiceMetric calculation\n",
    "            test_outputs_pt = [AsDiscrete(argmax=True, to_onehot=3)(i) for i in decollate_batch(test_outputs_pt)]\n",
    "            test_labels = [AsDiscrete(to_onehot=3)(i) for i in decollate_batch(test_labels)]\n",
    "\n",
    "            dice_metric_fn(y_pred=test_outputs_pt, y=test_labels)\n",
    "            dice_metric_batch_fn(y_pred=test_outputs_pt, y=test_labels)\n",
    "\n",
    "\n",
    "\n",
    "    # After processing all batches, save the outputs\n",
    "    pt_save_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/test_outputs_pt_saved.pt'\n",
    "    torch.save(test_outputs_pt, pt_save_path)\n",
    "    print(f\"Outputs saved at: {pt_save_path}\")\n",
    "    \n",
    "    \n",
    "    mean_dice_test = dice_metric_fn.aggregate().item()\n",
    "    metric_batch_test = dice_metric_batch_fn.aggregate()\n",
    "    metric_tumor = metric_batch_test[0].item()\n",
    "    metric_lymph = metric_batch_test[1].item()\n",
    "\n",
    "    print(f\"Testing - Avg Dice: {mean_dice_test:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "    return mean_dice_test, metric_tumor, metric_lymph\n",
    "    # Save the weights\n",
    "testing() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/nada.saadi/MIS-FM/hecktor2022_cropped'\n",
    "json_dir_ctpt = \"/home/nada.saadi/CTPET/hecktor2022_cropped/MDA_CTPT_TRAIN.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created at /home/nada.saadi/CTPET/hecktor2022_cropped/MDA_ctpt_test_new.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "def generate_paths(patient_id):\n",
    "    base_dir = '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data'\n",
    "    return {\n",
    "        'id': os.path.join(base_dir, patient_id),\n",
    "        'ct': os.path.join(base_dir, patient_id, f\"{patient_id}_ct.nii.gz\"),\n",
    "        'pt': os.path.join(base_dir, patient_id, f\"{patient_id}_pt.nii.gz\"),\n",
    "        'seg': os.path.join(base_dir, patient_id, f\"{patient_id}_gt.nii.gz\")\n",
    "    }\n",
    "\n",
    "# Assign each data entry to a random fold\n",
    "all_data = []\n",
    "num_folds = 5\n",
    "\n",
    "for file_dir in sorted(glob('data/*')):\n",
    "    patient_id = file_dir.split('/')[-1]\n",
    "    # Check if the file belongs to the MDA center\n",
    "    if patient_id.startswith(\"MDA-\"):\n",
    "        entry = generate_paths(patient_id)\n",
    "        entry['fold'] = random.randint(1, num_folds) - 1\n",
    "        all_data.append(entry)\n",
    "\n",
    "# Compile data into a JSON structure\n",
    "data_json = {\"training\": all_data}\n",
    "\n",
    "# Save to JSON file\n",
    "json_file_path = \"/home/nada.saadi/CTPET/hecktor2022_cropped/MDA_ctpt_test_new.json\"\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(data_json, f, indent=4)\n",
    "\n",
    "print(f\"JSON file created at {json_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data[key]\n",
    "\n",
    "    for d in json_data:\n",
    "        for k in d:\n",
    "            if isinstance(d[k], list):\n",
    "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "            elif isinstance(d[k], str):\n",
    "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "\n",
    "    tr = []\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "\n",
    "    return tr, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 44)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files, validation_files = datafold_read(datalist=json_dir_ctpt, basedir=data_dir, fold=0)\n",
    "len(train_files), len(validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a dictionary with the validation files\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mvalidation_files\u001b[49m}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save the dictionary to a JSON file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m json_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmda_ctpt_test_json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_files' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create a dictionary with the validation files\n",
    "validation_data = {\"validation\": validation_files}\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "json_file_path = \"mda_ctpt_test_json\"\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(validation_data, f, indent=4)\n",
    "\n",
    "print(f\"Validation files saved to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_ct.nii.gz', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_gt.nii.gz', 'fold': 0}\n",
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007/MDA-007_ct.nii.gz', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007/MDA-007_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007/MDA-007_gt.nii.gz', 'fold': 0}\n",
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015/MDA-015_ct.nii.gz', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015/MDA-015_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015/MDA-015_gt.nii.gz', 'fold': 0}\n",
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018/MDA-018_ct.nii.gz', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018/MDA-018_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018/MDA-018_gt.nii.gz', 'fold': 0}\n",
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028/MDA-028_ct.nii.gz', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028/MDA-028_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028/MDA-028_gt.nii.gz', 'fold': 0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = \"mda_ctpt_test_json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "   ctpt_data = json.load(file)\n",
    "\n",
    "# Print the first 5 elements\n",
    "for i in range(5):\n",
    "    print(ctpt_data[\"validation\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctpt_data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_dir_ctpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mjson_dir_ctpt\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     ctpt_data_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_dir_ctpt' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with open(json_dir_ctpt, 'r') as f:\n",
    "    ctpt_data_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctpt_data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms_ctpt = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\", \"pt\", \"seg\"], ensure_channel_first = True),\n",
    "        SpatialPadd(keys=[\"ct\", \"pt\", \"seg\"], spatial_size=(200, 200, 310), method='end'),\n",
    "        Orientationd(keys=[\"ct\", \"pt\", \"seg\"], axcodes=\"PLS\"),\n",
    "        NormalizeIntensityd(keys=[\"pt\"]),\n",
    "        ClipCT(keys=[\"ct\"]),\n",
    "        ScaleIntensityd(keys=[\"ct\"], minv=0, maxv=1),\n",
    "        #MulPTFM(keys=[\"ct\",\"pt\"]),\n",
    "        ConcatItemsd(keys=[\"pt\", \"ct\"], name=\"ctpt\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Dice Score: 0.4710\n",
      "Testing - Fused Avg Dice: 0.4710, Tumor Dice: 0.4293, Lymph Dice: 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:13<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=Dataset(data=ctpt_data[\"validation\"], transform=val_transforms_ctpt),\n",
    "    batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "# pt_weights='/home/nada.saadi/CTPET/hecktor2022_cropped/mda-ptonly-PT/ptonly-PT-with4.pth'\n",
    "# model_ct.load_state_dict(torch.load(pt_weights))\n",
    "def testing():\n",
    "    model_ct.eval()\n",
    "    model_pet.eval()\n",
    "    dice_metric_fn.reset()\n",
    "    dice_metric_batch_fn.reset()\n",
    "    \n",
    "    # Placeholder for fused outputs\n",
    "    fused_outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(test_loader):\n",
    "            test_inputs_ct, test_labels = batch_data[\"ct\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "            test_inputs_pt, test_labels = batch_data[\"pt\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "            # Generate outputs for both CT and PET models\n",
    "            test_outputs_ct = sliding_window_inference(test_inputs_ct, (96, 96, 96), 4, model_ct)\n",
    "            test_outputs_pt = sliding_window_inference(test_inputs_pt, (96, 96, 96), 4, model_pet)\n",
    "            \n",
    "            # Fuse the outputs\n",
    "            fused_outputs = 0*test_outputs_ct +  1*test_outputs_pt\n",
    "            \n",
    "            # Convert fused outputs to one-hot format for DiceMetric calculation\n",
    "            fused_outputs_onehot = [AsDiscrete(argmax=True, to_onehot=3)(i) for i in decollate_batch(fused_outputs)]\n",
    "            test_labels_onehot = [AsDiscrete(to_onehot=3)(i) for i in decollate_batch(test_labels)]\n",
    "            \n",
    "            # Append fused outputs for later Dice score calculation\n",
    "            fused_outputs_list.extend(fused_outputs_onehot)\n",
    "\n",
    "            # Calculate Dice score for fused output\n",
    "            dice_metric_fn(y_pred=fused_outputs_onehot, y=test_labels_onehot)\n",
    "            dice_metric_batch_fn(y_pred=fused_outputs_onehot, y=test_labels_onehot)\n",
    "            \n",
    "    # Aggregate the results for the entire dataset\n",
    "mean_dice_test = dice_metric_fn.aggregate().mean().item()\n",
    "print(f\"Overall Mean Dice Score: {mean_dice_test:.4f}\")\n",
    "metric_batch_test = dice_metric_batch_fn.aggregate()\n",
    "metric_tumor = metric_batch_test[0].item()\n",
    "metric_lymph = metric_batch_test[1].item()\n",
    "\n",
    "# def tensor_to_scalar(tensor):\n",
    "#     if torch.is_tensor(tensor) and tensor.numel() == 1:\n",
    "#         return tensor.item()\n",
    "#     elif not torch.is_tensor(tensor):\n",
    "#         return tensor  # Assume it's already a scalar if not a tensor\n",
    "#     else:\n",
    "#         raise ValueError(\"The tensor contains more than one element and cannot be converted to a scalar.\")\n",
    "    \n",
    "    \n",
    "# mean_dice_test_scalar = tensor_to_scalar(mean_dice_test)\n",
    "# metric_tumor_scalar = tensor_to_scalar(metric_tumor)\n",
    "# metric_lymph_scalar = tensor_to_scalar(metric_lymph)\n",
    "\n",
    "\n",
    " #Now, you can safely format these values with the format specifier\n",
    "print(f\"Testing - Fused Avg Dice: {mean_dice_test:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "   \n",
    "\n",
    "    # Save the fused outputs if needed\n",
    "# fused_save_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/fused_test_outputs_saved.pt'\n",
    "# torch.save(fused_outputs_list, fused_save_path)\n",
    "# print(f\"Fused outputs saved at: {fused_save_path}\")  \n",
    "#return mean_dice_test, metric_tumor, metric_lymph\n",
    "\n",
    "# # Ensure model_ct, model_pet, test_loader, and other necessary variables are correctly defined\n",
    "testing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created at /home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "def generate_paths(patient_id):\n",
    "    base_dir = '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data'\n",
    "    return {\n",
    "        \n",
    "        'seg': os.path.join(base_dir, patient_id, f\"{patient_id}_gt.nii.gz\")\n",
    "    }\n",
    "\n",
    "# Assign each data entry to a random fold\n",
    "all_data = []\n",
    "num_folds = 5\n",
    "\n",
    "for file_dir in sorted(glob('data/*')):\n",
    "    patient_id = file_dir.split('/')[-1]\n",
    "    # Check if the file belongs to the MDA center\n",
    "    if patient_id.startswith(\"MDA-\"):\n",
    "        entry = generate_paths(patient_id)\n",
    "        entry['fold'] = random.randint(1, num_folds) - 1\n",
    "        all_data.append(entry)\n",
    "\n",
    "# Compile data into a JSON structure\n",
    "data_json = {\"training\": all_data}\n",
    "\n",
    "# Save to JSON file\n",
    "json_file_path = \"/home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json\"\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(data_json, f, indent=4)\n",
    "\n",
    "print(f\"JSON file created at {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_gt.nii.gz', 'fold': 2}\n",
      "{'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-003/MDA-003_gt.nii.gz', 'fold': 3}\n",
      "{'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-004/MDA-004_gt.nii.gz', 'fold': 1}\n",
      "{'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005/MDA-005_gt.nii.gz', 'fold': 2}\n",
      "{'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-006/MDA-006_gt.nii.gz', 'fold': 0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = \"/home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    mda_labels = json.load(file)\n",
    "\n",
    "# Print the first 5 elements\n",
    "for i in range(5):\n",
    "    print(mda_labels[\"training\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the JSON file: 196\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = \"/home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Calculate the number of elements\n",
    "num_elements = len(data[\"training\"])\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of elements in the JSON file: {num_elements}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON file\n",
    "json_file_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json'\n",
    "\n",
    "# Reading the JSON data into a Python dictionary\n",
    "with open(json_file_path, 'r') as file:\n",
    "    labels_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming labels_dict values are the class indices and you know the number of classes\n",
    "num_classes = 3  # For example, if you have 3 classes: 0, 1, and 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All gt_ images from the MDA center have been stored in the destination directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source directory where the gt_ images are located\n",
    "source_directory = \"/home/nada.saadi/CTPET/hecktor2022_cropped/data\"\n",
    "\n",
    "# Define the destination directory where you want to store the gt_ images\n",
    "destination_directory = \"/home/nada.saadi/CTPET/hecktor2022_cropped/gt_images\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through the files in the source directory\n",
    "for root, dirs, files in os.walk(source_directory):\n",
    "    # Check if the file is a gt_ image from the MDA center\n",
    "    for file in files:\n",
    "        if \"MDA\" in file and file.endswith(\"_gt.nii.gz\"):\n",
    "            # Get the full path of the source file\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Get the destination file path by appending the file name to the destination directory\n",
    "            destination_file_path = os.path.join(destination_directory, file)\n",
    "            \n",
    "            # Copy the file to the destination directory\n",
    "            shutil.copy(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"All gt_ images from the MDA center have been stored in the destination directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def load_nifti_and_convert_to_onehot(image_path, num_classes):\n",
    "    \"\"\"\n",
    "    Loads a NIfTI segmentation image and converts it to a one-hot encoded tensor.\n",
    "    \n",
    "    Args:\n",
    "    - image_path (str): Path to the NIfTI segmentation image.\n",
    "    - num_classes (int): Total number of classes.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: One-hot encoded tensor of the segmentation with shape [num_classes, D, H, W],\n",
    "                    where D is the depth of the volume.\n",
    "    \"\"\"\n",
    "    # Load the NIfTI file\n",
    "    nifti_img = nib.load(image_path)\n",
    "    \n",
    "    # Convert the NIfTI file to a numpy array\n",
    "    image_array = nifti_img.get_fdata()\n",
    "    \n",
    "    # Initialize an empty tensor for the one-hot encoding\n",
    "    one_hot = torch.zeros((num_classes, *image_array.shape), dtype=torch.float32)\n",
    "    \n",
    "    # Fill the one-hot tensor\n",
    "    for c in range(num_classes):\n",
    "        one_hot[c] = torch.tensor(image_array == c, dtype=torch.float32)\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-006/MDA-006_gt.nii.gz'\n",
    "num_classes = 3  # Adjust based on your specific dataset\n",
    "one_hot_labels = load_nifti_and_convert_to_onehot(image_path, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load and convert all ground truth segmentations to one-hot encoding\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m onehot_labels_list \u001b[38;5;241m=\u001b[39m [load_nifti_and_convert_to_onehot(path, num_classes) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m labels_paths\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Stack the list of tensors into a single tensor for batch processing\u001b[39;00m\n\u001b[1;32m     28\u001b[0m onehot_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(onehot_labels_list)\n",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load and convert all ground truth segmentations to one-hot encoding\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m onehot_labels_list \u001b[38;5;241m=\u001b[39m [\u001b[43mload_nifti_and_convert_to_onehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m labels_paths\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Stack the list of tensors into a single tensor for batch processing\u001b[39;00m\n\u001b[1;32m     28\u001b[0m onehot_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(onehot_labels_list)\n",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m, in \u001b[0;36mload_nifti_and_convert_to_onehot\u001b[0;34m(image_path, num_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_nifti_and_convert_to_onehot\u001b[39m(image_path, num_classes):\n\u001b[0;32m----> 9\u001b[0m     nifti_img \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     image_array \u001b[38;5;241m=\u001b[39m nifti_img\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m     11\u001b[0m     one_hot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((num_classes, \u001b[38;5;241m*\u001b[39mimage_array\u001b[38;5;241m.\u001b[39mshape), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Check file exists and is not empty\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.metrics import DiceMetric\n",
    "import os\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "# Function to load NIfTI segmentation and convert to one-hot encoding (as discussed)\n",
    "def load_nifti_and_convert_to_onehot(image_path, num_classes):\n",
    "    nifti_img = nib.load(image_path)\n",
    "    image_array = nifti_img.get_fdata()\n",
    "    one_hot = torch.zeros((num_classes, *image_array.shape), dtype=torch.float32)\n",
    "    for c in range(num_classes):\n",
    "        one_hot[c] = torch.tensor(image_array == c, dtype=torch.float32)\n",
    "    return one_hot\n",
    "\n",
    "# Load the JSON file containing the paths to the ground truth NIfTI images\n",
    "json_file_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/mda_labels.json'\n",
    "with open(json_file_path, 'r') as file:\n",
    "    labels_paths = json.load(file)\n",
    "\n",
    "# Assuming num_classes is known\n",
    "num_classes = 3\n",
    "\n",
    "# Load and convert all ground truth segmentations to one-hot encoding\n",
    "onehot_labels_list = [load_nifti_and_convert_to_onehot(path, num_classes) for path in labels_paths.values()]\n",
    "\n",
    "# Stack the list of tensors into a single tensor for batch processing\n",
    "onehot_labels = torch.stack(onehot_labels_list)\n",
    "\n",
    "# Load the saved model outputs for CT and PET\n",
    "outputs_ct = torch.load('/home/nada.saadi/CTPET/hecktor2022_cropped/test_output_ct_saved.pt')\n",
    "outputs_pt = torch.load('/home/nada.saadi/CTPET/hecktor2022_cropped/test_outputs_pt_saved.pt')\n",
    "\n",
    "# Define the weights for CT and PET outputs and fuse them\n",
    "weight_ct = 0.2\n",
    "weight_pt = 0.8\n",
    "fused_outputs = weight_ct * outputs_ct + weight_pt * outputs_pt\n",
    "\n",
    "# Initialize DiceMetric for each class (excluding background)\n",
    "dice_metric_fn = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "\n",
    "# Calculate Dice scores using the fused outputs and the one-hot encoded labels\n",
    "dice_metric_fn.reset()\n",
    "dice_metric_fn(y_pred=fused_outputs, y=onehot_labels)\n",
    "\n",
    "metric_batch = dice_metric_fn.aggregate()\n",
    "metric_tumor = metric_batch[0].item()\n",
    "metric_lymph = metric_batch[1].item()\n",
    "mean_dice = sum(metric_batch) / len(metric_batch)\n",
    "\n",
    "print(f\"Fusion - Avg Dice: {mean_dice:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_masks(mask_ct, mask_pet, w_ct):\n",
    "    \"\"\"\n",
    "    Fuse two segmentation masks by a weighted sum.\n",
    "\n",
    "    Parameters:\n",
    "    - mask_ct (torch.Tensor): The segmentation mask from the CT model.\n",
    "    - mask_pet (torch.Tensor): The segmentation mask from the PET model.\n",
    "    - w_ct (float): The weight for the CT mask. Must be between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The fused segmentation mask.\n",
    "    \"\"\"\n",
    "    w_pet = 1 - w_ct\n",
    "    return w_ct * mask_ct + w_pet * mask_pet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_outputs_ct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have the test outputs of the CT and PET models stored in variables `test_output_ct` and `test_output_pet` respectively\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Apply softmax to the test outputs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_output_ct_softmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mtest_outputs_ct\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_output_pet_softmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(test_outputs_pet, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fuse the test outputs with the specified weights\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_outputs_ct' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have the test outputs of the CT and PET models stored in variables `test_output_ct` and `test_output_pet` respectively\n",
    "test_outputs_ct = sliding_window_inference(test_inputs, (96, 96, 96), 4, model_pet)\n",
    "test_outputs_pet = ...\n",
    "\n",
    "# Apply softmax to the test outputs\n",
    "test_output_ct_softmax = torch.softmax(test_outputs_ct, dim=1)\n",
    "test_output_pet_softmax = torch.softmax(test_outputs_pet, dim=1)\n",
    "\n",
    "# Fuse the test outputs with the specified weights\n",
    "fused_output = fuse_masks(test_output_ct_softmax, test_output_pet_softmax, w_ct=0.2)\n",
    "\n",
    "# You can then use the fused output for further analysis or evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_outputs_ct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m w_ct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      2\u001b[0m w_pet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m w_ct\n\u001b[0;32m----> 3\u001b[0m lf\u001b[38;5;241m=\u001b[39mw_ct\u001b[38;5;241m*\u001b[39m\u001b[43mtest_outputs_ct\u001b[49m \u001b[38;5;241m+\u001b[39m w_pet\u001b[38;5;241m*\u001b[39mtest_outputs_pt\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_outputs_ct' is not defined"
     ]
    }
   ],
   "source": [
    "w_ct = 0.2\n",
    "w_pet = 1 - w_ct\n",
    "lf=w_ct*test_outputs_ct + w_pet*test_outputs_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m pet_image \u001b[38;5;241m=\u001b[39m load_and_preprocess_image(pet_image_path, modality\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPET\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors and add batch dimension if necessary\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Example: ct_image and pet_image are numpy arrays after preprocessing\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m ct_image_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct_image\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [1, C, H, W, D]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pet_image_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(pet_image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [1, C, H, W, D]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got NoneType)"
     ]
    }
   ],
   "source": [
    "# Dummy function for illustration\n",
    "def load_and_preprocess_image(image_path, target_size=(96, 96, 96), modality='CT'):\n",
    "    # Implement your loading and preprocessing logic here\n",
    "    # This might involve reading the image, resampling, normalizing, etc.\n",
    "    # Return the processed image as a numpy array\n",
    "    return processed_image\n",
    "\n",
    "# Load and preprocess the CT and PET images\n",
    "ct_image_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/data/MDA-183/MDA-183_ct.nii.gz'\n",
    "pet_image_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/data/MDA-183/MDA-183_pt.nii.gz'\n",
    "\n",
    "ct_image = load_and_preprocess_image(ct_image_path, modality='CT')\n",
    "pet_image = load_and_preprocess_image(pet_image_path, modality='PET')\n",
    "\n",
    "# Convert to PyTorch tensors and add batch dimension if necessary\n",
    "# Example: ct_image and pet_image are numpy arrays after preprocessing\n",
    "ct_image_tensor = torch.from_numpy(ct_image).unsqueeze(0).to(device)  # Shape: [1, C, H, W, D]\n",
    "pet_image_tensor = torch.from_numpy(pet_image).unsqueeze(0).to(device)  # Shape: [1, C, H, W, D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No need to compute gradients\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Assuming ct_image and pet_image are tensors of shape [1, C, H, W, D]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     output_ct \u001b[38;5;241m=\u001b[39m \u001b[43mct_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/nada.saadi/CTPET/hecktor2022_cropped/data/MDA-183/MDA-183_ct.nii.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     output_pet \u001b[38;5;241m=\u001b[39m pet_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/nada.saadi/CTPET/hecktor2022_cropped/data/MDA-183/MDA-183_pt.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Assuming the output masks are logits; apply softmax if needed\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # No need to compute gradients\n",
    "    # Assuming ct_image and pet_image are tensors of shape [1, C, H, W, D]\n",
    "    output_ct = ct_model\n",
    "    output_pet = pet_model\n",
    "\n",
    "    # Assuming the output masks are logits; apply softmax if needed\n",
    "    mask_ct = torch.softmax(output_ct, dim=1)\n",
    "    mask_pet = torch.softmax(output_pet, dim=1)\n",
    "\n",
    "    # Fuse the masks\n",
    "    w_ct = 0.2  # Example weight, adjust as needed\n",
    "    fused_mask = fuse_masks(mask_ct, mask_pet, w_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
