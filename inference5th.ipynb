{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ct_only= '/home/nada.saadi/CTPET/hecktor2022_cropped/test_ct_only_mda.json'\n",
    "test_pet_only= '/home/nada.saadi/CTPET/hecktor2022_cropped/test_pet_only_mda.json'\n",
    "test_CTPT= '/home/nada.saadi/CTPET/hecktor2022_cropped/test_CTPT_only_mda.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder_frozen_PT_weights='/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf/m2-withpet-intheskipconnection-firsthalf.pth'\n",
    "Encoder_decoder_frozen_PT_weights= '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf-decoderfrozen/m2-withpet-intheskipconnection-firsthalf-decoderfrozen.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1215655/2558345750.py:9: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from collections.abc import Sequence\n",
    "\n",
    "from unetr import CustomedUNETR\n",
    "\n",
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "\n",
    "print(torch.cuda.device_count()) \n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import EnsureTyped\n",
    "from monai.transforms import Compose, LoadImaged, ScaleIntensityRanged, ConcatItemsd\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceCELoss, DiceFocalLoss, FocalLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "\n",
    "from monai.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    MapTransform,\n",
    "    ScaleIntensityd,\n",
    "    #AddChanneld,\n",
    "    SpatialPadd,\n",
    "    CenterSpatialCropd,\n",
    "    EnsureChannelFirstd,\n",
    "    ConcatItemsd,\n",
    "    AdjustContrastd, \n",
    "    Rand3DElasticd,\n",
    "    HistogramNormalized,\n",
    "    NormalizeIntensityd,\n",
    "    Invertd,\n",
    "    SaveImage,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/nada.saadi/MIS-FM/hecktor2022_cropped'\n",
    "json_dir=test_ct_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nada.saadi/miniconda3/envs/clam/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: unetr CustomedUNETR.__init__:pos_embed: Argument `pos_embed` has been deprecated since version 1.2. It will be removed in version 1.4. please use `proj_type` instead.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nada's version of UNETR\n",
      "(96, 96, 96)\n",
      "(16, 16, 16)\n",
      "(6, 6, 6)\n",
      "768\n",
      "zaz w dakchi ya s lbnat\n"
     ]
    }
   ],
   "source": [
    "model = CustomedUNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=48,\n",
    "    hidden_size=768,\n",
    "    num_heads=12,\n",
    "    mlp_dim=3072,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    "    proj_type=\"conv\",\n",
    "    use_ct_encoder=True,  # Disable CT encoder\n",
    "    use_pet_encoder=False,  # Disable PET encoder for CT-only inference\n",
    "    use_lora=False,  # Disable LoRA\n",
    "    \n",
    "    \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomedUNETR(\n",
       "  (vit): ViT(\n",
       "    (patch_embedding): PatchEmbeddingBlock(\n",
       "      (patch_embeddings): Conv3d(1, 768, kernel_size=(16, 16, 16), stride=(16, 16, 16))\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x TransformerBlock(\n",
       "        (mlp): MLPBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (fn): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SABlock(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (proj_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (proj_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (input_rearrange): Rearrange('b h (l d) -> b l h d', l=12)\n",
       "          (out_rearrange): Rearrange('b h l d -> b l (h d)')\n",
       "          (drop_output): Dropout(p=0.0, inplace=False)\n",
       "          (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(1, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder1_pt): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(1, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): ConvTranspose3d(192, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): UnetResBlock(\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          )\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrPrUpBlock(\n",
       "    (transp_conv_init): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList()\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(48, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['vit.patch_embedding.position_embeddings', 'vit.patch_embedding.patch_embeddings.weight', 'vit.patch_embedding.patch_embeddings.bias', 'vit.blocks.0.mlp.linear1.weight', 'vit.blocks.0.mlp.linear1.bias', 'vit.blocks.0.mlp.linear2.weight', 'vit.blocks.0.mlp.linear2.bias', 'vit.blocks.0.norm1.weight', 'vit.blocks.0.norm1.bias', 'vit.blocks.0.attn.out_proj.weight', 'vit.blocks.0.attn.out_proj.bias', 'vit.blocks.0.attn.proj_q.weight', 'vit.blocks.0.attn.proj_k.weight', 'vit.blocks.0.attn.proj_v.weight', 'vit.blocks.0.norm2.weight', 'vit.blocks.0.norm2.bias', 'vit.blocks.1.mlp.linear1.weight', 'vit.blocks.1.mlp.linear1.bias', 'vit.blocks.1.mlp.linear2.weight', 'vit.blocks.1.mlp.linear2.bias', 'vit.blocks.1.norm1.weight', 'vit.blocks.1.norm1.bias', 'vit.blocks.1.attn.out_proj.weight', 'vit.blocks.1.attn.out_proj.bias', 'vit.blocks.1.attn.proj_q.weight', 'vit.blocks.1.attn.proj_k.weight', 'vit.blocks.1.attn.proj_v.weight', 'vit.blocks.1.norm2.weight', 'vit.blocks.1.norm2.bias', 'vit.blocks.2.mlp.linear1.weight', 'vit.blocks.2.mlp.linear1.bias', 'vit.blocks.2.mlp.linear2.weight', 'vit.blocks.2.mlp.linear2.bias', 'vit.blocks.2.norm1.weight', 'vit.blocks.2.norm1.bias', 'vit.blocks.2.attn.out_proj.weight', 'vit.blocks.2.attn.out_proj.bias', 'vit.blocks.2.attn.proj_q.weight', 'vit.blocks.2.attn.proj_k.weight', 'vit.blocks.2.attn.proj_v.weight', 'vit.blocks.2.norm2.weight', 'vit.blocks.2.norm2.bias', 'vit.blocks.3.mlp.linear1.weight', 'vit.blocks.3.mlp.linear1.bias', 'vit.blocks.3.mlp.linear2.weight', 'vit.blocks.3.mlp.linear2.bias', 'vit.blocks.3.norm1.weight', 'vit.blocks.3.norm1.bias', 'vit.blocks.3.attn.out_proj.weight', 'vit.blocks.3.attn.out_proj.bias', 'vit.blocks.3.attn.proj_q.weight', 'vit.blocks.3.attn.proj_k.weight', 'vit.blocks.3.attn.proj_v.weight', 'vit.blocks.3.norm2.weight', 'vit.blocks.3.norm2.bias', 'vit.blocks.4.mlp.linear1.weight', 'vit.blocks.4.mlp.linear1.bias', 'vit.blocks.4.mlp.linear2.weight', 'vit.blocks.4.mlp.linear2.bias', 'vit.blocks.4.norm1.weight', 'vit.blocks.4.norm1.bias', 'vit.blocks.4.attn.out_proj.weight', 'vit.blocks.4.attn.out_proj.bias', 'vit.blocks.4.attn.proj_q.weight', 'vit.blocks.4.attn.proj_k.weight', 'vit.blocks.4.attn.proj_v.weight', 'vit.blocks.4.norm2.weight', 'vit.blocks.4.norm2.bias', 'vit.blocks.5.mlp.linear1.weight', 'vit.blocks.5.mlp.linear1.bias', 'vit.blocks.5.mlp.linear2.weight', 'vit.blocks.5.mlp.linear2.bias', 'vit.blocks.5.norm1.weight', 'vit.blocks.5.norm1.bias', 'vit.blocks.5.attn.out_proj.weight', 'vit.blocks.5.attn.out_proj.bias', 'vit.blocks.5.attn.proj_q.weight', 'vit.blocks.5.attn.proj_k.weight', 'vit.blocks.5.attn.proj_v.weight', 'vit.blocks.5.norm2.weight', 'vit.blocks.5.norm2.bias', 'vit.blocks.6.mlp.linear1.weight', 'vit.blocks.6.mlp.linear1.bias', 'vit.blocks.6.mlp.linear2.weight', 'vit.blocks.6.mlp.linear2.bias', 'vit.blocks.6.norm1.weight', 'vit.blocks.6.norm1.bias', 'vit.blocks.6.attn.out_proj.weight', 'vit.blocks.6.attn.out_proj.bias', 'vit.blocks.6.attn.proj_q.weight', 'vit.blocks.6.attn.proj_k.weight', 'vit.blocks.6.attn.proj_v.weight', 'vit.blocks.6.norm2.weight', 'vit.blocks.6.norm2.bias', 'vit.blocks.7.mlp.linear1.weight', 'vit.blocks.7.mlp.linear1.bias', 'vit.blocks.7.mlp.linear2.weight', 'vit.blocks.7.mlp.linear2.bias', 'vit.blocks.7.norm1.weight', 'vit.blocks.7.norm1.bias', 'vit.blocks.7.attn.out_proj.weight', 'vit.blocks.7.attn.out_proj.bias', 'vit.blocks.7.attn.proj_q.weight', 'vit.blocks.7.attn.proj_k.weight', 'vit.blocks.7.attn.proj_v.weight', 'vit.blocks.7.norm2.weight', 'vit.blocks.7.norm2.bias', 'vit.blocks.8.mlp.linear1.weight', 'vit.blocks.8.mlp.linear1.bias', 'vit.blocks.8.mlp.linear2.weight', 'vit.blocks.8.mlp.linear2.bias', 'vit.blocks.8.norm1.weight', 'vit.blocks.8.norm1.bias', 'vit.blocks.8.attn.out_proj.weight', 'vit.blocks.8.attn.out_proj.bias', 'vit.blocks.8.attn.proj_q.weight', 'vit.blocks.8.attn.proj_k.weight', 'vit.blocks.8.attn.proj_v.weight', 'vit.blocks.8.norm2.weight', 'vit.blocks.8.norm2.bias', 'vit.blocks.9.mlp.linear1.weight', 'vit.blocks.9.mlp.linear1.bias', 'vit.blocks.9.mlp.linear2.weight', 'vit.blocks.9.mlp.linear2.bias', 'vit.blocks.9.norm1.weight', 'vit.blocks.9.norm1.bias', 'vit.blocks.9.attn.out_proj.weight', 'vit.blocks.9.attn.out_proj.bias', 'vit.blocks.9.attn.proj_q.weight', 'vit.blocks.9.attn.proj_k.weight', 'vit.blocks.9.attn.proj_v.weight', 'vit.blocks.9.norm2.weight', 'vit.blocks.9.norm2.bias', 'vit.blocks.10.mlp.linear1.weight', 'vit.blocks.10.mlp.linear1.bias', 'vit.blocks.10.mlp.linear2.weight', 'vit.blocks.10.mlp.linear2.bias', 'vit.blocks.10.norm1.weight', 'vit.blocks.10.norm1.bias', 'vit.blocks.10.attn.out_proj.weight', 'vit.blocks.10.attn.out_proj.bias', 'vit.blocks.10.attn.proj_q.weight', 'vit.blocks.10.attn.proj_k.weight', 'vit.blocks.10.attn.proj_v.weight', 'vit.blocks.10.norm2.weight', 'vit.blocks.10.norm2.bias', 'vit.blocks.11.mlp.linear1.weight', 'vit.blocks.11.mlp.linear1.bias', 'vit.blocks.11.mlp.linear2.weight', 'vit.blocks.11.mlp.linear2.bias', 'vit.blocks.11.norm1.weight', 'vit.blocks.11.norm1.bias', 'vit.blocks.11.attn.out_proj.weight', 'vit.blocks.11.attn.out_proj.bias', 'vit.blocks.11.attn.proj_q.weight', 'vit.blocks.11.attn.proj_k.weight', 'vit.blocks.11.attn.proj_v.weight', 'vit.blocks.11.norm2.weight', 'vit.blocks.11.norm2.bias', 'vit.norm.weight', 'vit.norm.bias', 'encoder1.layer.conv1.conv.weight', 'encoder1.layer.conv2.conv.weight', 'encoder1.layer.conv3.conv.weight', 'encoder1_pt.layer.conv1.conv.weight', 'encoder1_pt.layer.conv2.conv.weight', 'encoder1_pt.layer.conv3.conv.weight', 'encoder2.transp_conv_init.conv.weight', 'encoder2.blocks.0.0.conv.weight', 'encoder2.blocks.0.1.conv1.conv.weight', 'encoder2.blocks.0.1.conv2.conv.weight', 'encoder2.blocks.1.0.conv.weight', 'encoder2.blocks.1.1.conv1.conv.weight', 'encoder2.blocks.1.1.conv2.conv.weight', 'encoder3.transp_conv_init.conv.weight', 'encoder3.blocks.0.0.conv.weight', 'encoder3.blocks.0.1.conv1.conv.weight', 'encoder3.blocks.0.1.conv2.conv.weight', 'encoder4.transp_conv_init.conv.weight', 'decoder5.transp_conv.conv.weight', 'decoder5.conv_block.conv1.conv.weight', 'decoder5.conv_block.conv2.conv.weight', 'decoder5.conv_block.conv3.conv.weight', 'decoder4.transp_conv.conv.weight', 'decoder4.conv_block.conv1.conv.weight', 'decoder4.conv_block.conv2.conv.weight', 'decoder4.conv_block.conv3.conv.weight', 'decoder3.transp_conv.conv.weight', 'decoder3.conv_block.conv1.conv.weight', 'decoder3.conv_block.conv2.conv.weight', 'decoder3.conv_block.conv3.conv.weight', 'decoder2.transp_conv.conv.weight', 'decoder2.conv_block.conv1.conv.weight', 'decoder2.conv_block.conv2.conv.weight', 'decoder2.conv_block.conv3.conv.weight', 'out.conv.conv.weight', 'out.conv.conv.bias'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipCT(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on hecktor classes:\n",
    "    label 1 is the tumor\n",
    "    label 2 is the lymph node\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            if key == \"ct\":\n",
    "                d[key] = torch.clip(d[key], min=-200, max=200)\n",
    "            # elif key == \"pt\":\n",
    "            #     d[key] = torch.clip(d[key], d[key].min(), 5)\n",
    "        return d\n",
    "\n",
    "class MulPTFM(MapTransform):\n",
    "    \"\"\"\n",
    "    Mult PT and FM \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "\n",
    "        fm = d[\"ct\"] > 0\n",
    "        d[\"pt\"] = d[\"pt\"] * fm\n",
    "        return d\n",
    "\n",
    "class SelectClass(MapTransform):\n",
    "    \"\"\"\n",
    "    Select the class for which you want to fine tune the model \n",
    "\n",
    "    \"\"\"\n",
    "    # def __init__(self, keys, cls=1):\n",
    "    #     super(self).__init__(keys)\n",
    "    #     self.cls = cls\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        d[\"seg\"][d[\"seg\"] == 1] = 0\n",
    "        # d[\"seg\"][d[\"seg\"] == 2] = 1\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafold_read(datalist, basedir, fold=0):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold and \"key\" not in d:\n",
    "            for k in d:\n",
    "                if isinstance(d[k], list):\n",
    "                    d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "                elif isinstance(d[k], str):\n",
    "                    d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "            val.append(d)\n",
    "\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005', 'pt': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005/MDA-005_pt.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-005/MDA-005_gt.nii.gz', 'fold': 0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the file\n",
    "with open('/home/nada.saadi/CTPET/hecktor2022_cropped/test_pet_only_mda.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print the first dictionary\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_valid_data = datafold_read(datalist=json_dir, basedir=data_dir, fold=0)\n",
    "len(modified_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_transforms = Compose(\n",
    "#     [\n",
    "#         LoadImaged(keys=[ \"pt\", \"seg\"], ensure_channel_first = True),\n",
    "#         SpatialPadd(keys=[ \"pt\", \"seg\"], spatial_size=(200, 200, 310), method='end'),\n",
    "#         Orientationd(keys=[ \"pt\", \"seg\"], axcodes=\"PLS\"),\n",
    "#         NormalizeIntensityd(keys=[\"pt\"]),\n",
    "#         ClipCT(keys=[\"pt\"]),\n",
    "#         ScaleIntensityd(keys=[\"pt\"], minv=0, maxv=1),\n",
    "#         #MulPTFM(keys=[\"ct\",\"pt\"]),\n",
    "#         ConcatItemsd(keys=[\"pt\"], name=\"pt\"),\n",
    "#     ]\n",
    "# )\n",
    "# def create_dataloader(data, transforms, batch_size=2, shuffle=True):\n",
    "#     # Create CacheDataset with the reformatted data\n",
    "#     dataset = Dataset(data=data, transform=transforms)\n",
    "\n",
    "#     # Create DataLoader\n",
    "#     return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "# val_loader = create_dataloader(modified_valid_data, val_transforms, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ct\",  \"seg\"], ensure_channel_first = True),\n",
    "        SpatialPadd(keys=[\"ct\",  \"seg\"], spatial_size=(200, 200, 310), method='end'),\n",
    "        Orientationd(keys=[\"ct\",  \"seg\"], axcodes=\"PLS\"),\n",
    "        #NormalizeIntensityd(keys=[\"pt\"]),\n",
    "        ClipCT(keys=[\"ct\"]),\n",
    "        ScaleIntensityd(keys=[\"ct\",], minv=0, maxv=1),\n",
    "        #MulPTFM(keys=[\"ct\",\"pt\"]),\n",
    "        ConcatItemsd(keys=[ \"ct\"], name=\"ct\"),\n",
    "    ]\n",
    ")\n",
    "def create_dataloader(data, transforms, batch_size=2, shuffle=True):\n",
    "    # Create CacheDataset with the reformatted data\n",
    "    dataset = Dataset(data=data, transform=transforms)\n",
    "\n",
    "    # Create DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "val_loader = create_dataloader(ct_data, val_transforms, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "def poly_lr(epoch, max_epochs, initial_lr, exponent=0.9):\n",
    "    return initial_lr * (1 - epoch / max_epochs)**exponent\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['vit.lora_vit.patch_embedding.position_embeddings', 'vit.lora_vit.patch_embedding.patch_embeddings.weight', 'vit.lora_vit.patch_embedding.patch_embeddings.bias', 'vit.lora_vit.blocks.0.mlp.linear1.weight', 'vit.lora_vit.blocks.0.mlp.linear1.bias', 'vit.lora_vit.blocks.0.mlp.linear2.weight', 'vit.lora_vit.blocks.0.mlp.linear2.bias', 'vit.lora_vit.blocks.0.norm1.weight', 'vit.lora_vit.blocks.0.norm1.bias', 'vit.lora_vit.blocks.0.attn.out_proj.weight', 'vit.lora_vit.blocks.0.attn.out_proj.bias', 'vit.lora_vit.blocks.0.attn.proj_q.w.weight', 'vit.lora_vit.blocks.0.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.0.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.0.attn.proj_k.weight', 'vit.lora_vit.blocks.0.attn.proj_v.w.weight', 'vit.lora_vit.blocks.0.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.0.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.0.norm2.weight', 'vit.lora_vit.blocks.0.norm2.bias', 'vit.lora_vit.blocks.1.mlp.linear1.weight', 'vit.lora_vit.blocks.1.mlp.linear1.bias', 'vit.lora_vit.blocks.1.mlp.linear2.weight', 'vit.lora_vit.blocks.1.mlp.linear2.bias', 'vit.lora_vit.blocks.1.norm1.weight', 'vit.lora_vit.blocks.1.norm1.bias', 'vit.lora_vit.blocks.1.attn.out_proj.weight', 'vit.lora_vit.blocks.1.attn.out_proj.bias', 'vit.lora_vit.blocks.1.attn.proj_q.w.weight', 'vit.lora_vit.blocks.1.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.1.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.1.attn.proj_k.weight', 'vit.lora_vit.blocks.1.attn.proj_v.w.weight', 'vit.lora_vit.blocks.1.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.1.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.1.norm2.weight', 'vit.lora_vit.blocks.1.norm2.bias', 'vit.lora_vit.blocks.2.mlp.linear1.weight', 'vit.lora_vit.blocks.2.mlp.linear1.bias', 'vit.lora_vit.blocks.2.mlp.linear2.weight', 'vit.lora_vit.blocks.2.mlp.linear2.bias', 'vit.lora_vit.blocks.2.norm1.weight', 'vit.lora_vit.blocks.2.norm1.bias', 'vit.lora_vit.blocks.2.attn.out_proj.weight', 'vit.lora_vit.blocks.2.attn.out_proj.bias', 'vit.lora_vit.blocks.2.attn.proj_q.w.weight', 'vit.lora_vit.blocks.2.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.2.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.2.attn.proj_k.weight', 'vit.lora_vit.blocks.2.attn.proj_v.w.weight', 'vit.lora_vit.blocks.2.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.2.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.2.norm2.weight', 'vit.lora_vit.blocks.2.norm2.bias', 'vit.lora_vit.blocks.3.mlp.linear1.weight', 'vit.lora_vit.blocks.3.mlp.linear1.bias', 'vit.lora_vit.blocks.3.mlp.linear2.weight', 'vit.lora_vit.blocks.3.mlp.linear2.bias', 'vit.lora_vit.blocks.3.norm1.weight', 'vit.lora_vit.blocks.3.norm1.bias', 'vit.lora_vit.blocks.3.attn.out_proj.weight', 'vit.lora_vit.blocks.3.attn.out_proj.bias', 'vit.lora_vit.blocks.3.attn.proj_q.w.weight', 'vit.lora_vit.blocks.3.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.3.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.3.attn.proj_k.weight', 'vit.lora_vit.blocks.3.attn.proj_v.w.weight', 'vit.lora_vit.blocks.3.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.3.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.3.norm2.weight', 'vit.lora_vit.blocks.3.norm2.bias', 'vit.lora_vit.blocks.4.mlp.linear1.weight', 'vit.lora_vit.blocks.4.mlp.linear1.bias', 'vit.lora_vit.blocks.4.mlp.linear2.weight', 'vit.lora_vit.blocks.4.mlp.linear2.bias', 'vit.lora_vit.blocks.4.norm1.weight', 'vit.lora_vit.blocks.4.norm1.bias', 'vit.lora_vit.blocks.4.attn.out_proj.weight', 'vit.lora_vit.blocks.4.attn.out_proj.bias', 'vit.lora_vit.blocks.4.attn.proj_q.w.weight', 'vit.lora_vit.blocks.4.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.4.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.4.attn.proj_k.weight', 'vit.lora_vit.blocks.4.attn.proj_v.w.weight', 'vit.lora_vit.blocks.4.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.4.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.4.norm2.weight', 'vit.lora_vit.blocks.4.norm2.bias', 'vit.lora_vit.blocks.5.mlp.linear1.weight', 'vit.lora_vit.blocks.5.mlp.linear1.bias', 'vit.lora_vit.blocks.5.mlp.linear2.weight', 'vit.lora_vit.blocks.5.mlp.linear2.bias', 'vit.lora_vit.blocks.5.norm1.weight', 'vit.lora_vit.blocks.5.norm1.bias', 'vit.lora_vit.blocks.5.attn.out_proj.weight', 'vit.lora_vit.blocks.5.attn.out_proj.bias', 'vit.lora_vit.blocks.5.attn.proj_q.w.weight', 'vit.lora_vit.blocks.5.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.5.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.5.attn.proj_k.weight', 'vit.lora_vit.blocks.5.attn.proj_v.w.weight', 'vit.lora_vit.blocks.5.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.5.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.5.norm2.weight', 'vit.lora_vit.blocks.5.norm2.bias', 'vit.lora_vit.blocks.6.mlp.linear1.weight', 'vit.lora_vit.blocks.6.mlp.linear1.bias', 'vit.lora_vit.blocks.6.mlp.linear2.weight', 'vit.lora_vit.blocks.6.mlp.linear2.bias', 'vit.lora_vit.blocks.6.norm1.weight', 'vit.lora_vit.blocks.6.norm1.bias', 'vit.lora_vit.blocks.6.attn.out_proj.weight', 'vit.lora_vit.blocks.6.attn.out_proj.bias', 'vit.lora_vit.blocks.6.attn.proj_q.w.weight', 'vit.lora_vit.blocks.6.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.6.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.6.attn.proj_k.weight', 'vit.lora_vit.blocks.6.attn.proj_v.w.weight', 'vit.lora_vit.blocks.6.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.6.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.6.norm2.weight', 'vit.lora_vit.blocks.6.norm2.bias', 'vit.lora_vit.blocks.7.mlp.linear1.weight', 'vit.lora_vit.blocks.7.mlp.linear1.bias', 'vit.lora_vit.blocks.7.mlp.linear2.weight', 'vit.lora_vit.blocks.7.mlp.linear2.bias', 'vit.lora_vit.blocks.7.norm1.weight', 'vit.lora_vit.blocks.7.norm1.bias', 'vit.lora_vit.blocks.7.attn.out_proj.weight', 'vit.lora_vit.blocks.7.attn.out_proj.bias', 'vit.lora_vit.blocks.7.attn.proj_q.w.weight', 'vit.lora_vit.blocks.7.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.7.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.7.attn.proj_k.weight', 'vit.lora_vit.blocks.7.attn.proj_v.w.weight', 'vit.lora_vit.blocks.7.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.7.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.7.norm2.weight', 'vit.lora_vit.blocks.7.norm2.bias', 'vit.lora_vit.blocks.8.mlp.linear1.weight', 'vit.lora_vit.blocks.8.mlp.linear1.bias', 'vit.lora_vit.blocks.8.mlp.linear2.weight', 'vit.lora_vit.blocks.8.mlp.linear2.bias', 'vit.lora_vit.blocks.8.norm1.weight', 'vit.lora_vit.blocks.8.norm1.bias', 'vit.lora_vit.blocks.8.attn.out_proj.weight', 'vit.lora_vit.blocks.8.attn.out_proj.bias', 'vit.lora_vit.blocks.8.attn.proj_q.w.weight', 'vit.lora_vit.blocks.8.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.8.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.8.attn.proj_k.weight', 'vit.lora_vit.blocks.8.attn.proj_v.w.weight', 'vit.lora_vit.blocks.8.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.8.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.8.norm2.weight', 'vit.lora_vit.blocks.8.norm2.bias', 'vit.lora_vit.blocks.9.mlp.linear1.weight', 'vit.lora_vit.blocks.9.mlp.linear1.bias', 'vit.lora_vit.blocks.9.mlp.linear2.weight', 'vit.lora_vit.blocks.9.mlp.linear2.bias', 'vit.lora_vit.blocks.9.norm1.weight', 'vit.lora_vit.blocks.9.norm1.bias', 'vit.lora_vit.blocks.9.attn.out_proj.weight', 'vit.lora_vit.blocks.9.attn.out_proj.bias', 'vit.lora_vit.blocks.9.attn.proj_q.w.weight', 'vit.lora_vit.blocks.9.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.9.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.9.attn.proj_k.weight', 'vit.lora_vit.blocks.9.attn.proj_v.w.weight', 'vit.lora_vit.blocks.9.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.9.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.9.norm2.weight', 'vit.lora_vit.blocks.9.norm2.bias', 'vit.lora_vit.blocks.10.mlp.linear1.weight', 'vit.lora_vit.blocks.10.mlp.linear1.bias', 'vit.lora_vit.blocks.10.mlp.linear2.weight', 'vit.lora_vit.blocks.10.mlp.linear2.bias', 'vit.lora_vit.blocks.10.norm1.weight', 'vit.lora_vit.blocks.10.norm1.bias', 'vit.lora_vit.blocks.10.attn.out_proj.weight', 'vit.lora_vit.blocks.10.attn.out_proj.bias', 'vit.lora_vit.blocks.10.attn.proj_q.w.weight', 'vit.lora_vit.blocks.10.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.10.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.10.attn.proj_k.weight', 'vit.lora_vit.blocks.10.attn.proj_v.w.weight', 'vit.lora_vit.blocks.10.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.10.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.10.norm2.weight', 'vit.lora_vit.blocks.10.norm2.bias', 'vit.lora_vit.blocks.11.mlp.linear1.weight', 'vit.lora_vit.blocks.11.mlp.linear1.bias', 'vit.lora_vit.blocks.11.mlp.linear2.weight', 'vit.lora_vit.blocks.11.mlp.linear2.bias', 'vit.lora_vit.blocks.11.norm1.weight', 'vit.lora_vit.blocks.11.norm1.bias', 'vit.lora_vit.blocks.11.attn.out_proj.weight', 'vit.lora_vit.blocks.11.attn.out_proj.bias', 'vit.lora_vit.blocks.11.attn.proj_q.w.weight', 'vit.lora_vit.blocks.11.attn.proj_q.w_a.weight', 'vit.lora_vit.blocks.11.attn.proj_q.w_b.weight', 'vit.lora_vit.blocks.11.attn.proj_k.weight', 'vit.lora_vit.blocks.11.attn.proj_v.w.weight', 'vit.lora_vit.blocks.11.attn.proj_v.w_a.weight', 'vit.lora_vit.blocks.11.attn.proj_v.w_b.weight', 'vit.lora_vit.blocks.11.norm2.weight', 'vit.lora_vit.blocks.11.norm2.bias', 'vit.lora_vit.norm.weight', 'vit.lora_vit.norm.bias', 'encoder1.layer.conv1.conv.weight', 'encoder1.layer.conv2.conv.weight', 'encoder1.layer.conv3.conv.weight', 'encoder1_pt.layer.conv1.conv.weight', 'encoder1_pt.layer.conv2.conv.weight', 'encoder1_pt.layer.conv3.conv.weight', 'encoder2.transp_conv_init.conv.weight', 'encoder2.blocks.0.0.conv.weight', 'encoder2.blocks.0.1.conv1.conv.weight', 'encoder2.blocks.0.1.conv2.conv.weight', 'encoder2.blocks.1.0.conv.weight', 'encoder2.blocks.1.1.conv1.conv.weight', 'encoder2.blocks.1.1.conv2.conv.weight', 'encoder3.transp_conv_init.conv.weight', 'encoder3.blocks.0.0.conv.weight', 'encoder3.blocks.0.1.conv1.conv.weight', 'encoder3.blocks.0.1.conv2.conv.weight', 'encoder4.transp_conv_init.conv.weight', 'decoder5.transp_conv.conv.weight', 'decoder5.conv_block.conv1.conv.weight', 'decoder5.conv_block.conv2.conv.weight', 'decoder5.conv_block.conv3.conv.weight', 'decoder4.transp_conv.conv.weight', 'decoder4.conv_block.conv1.conv.weight', 'decoder4.conv_block.conv2.conv.weight', 'decoder4.conv_block.conv3.conv.weight', 'decoder3.transp_conv.conv.weight', 'decoder3.conv_block.conv1.conv.weight', 'decoder3.conv_block.conv2.conv.weight', 'decoder3.conv_block.conv3.conv.weight', 'decoder2.transp_conv.conv.weight', 'decoder2.conv_block.conv1.conv.weight', 'decoder2.conv_block.conv2.conv.weight', 'decoder2.conv_block.conv3.conv.weight', 'out.conv.conv.weight', 'out.conv.conv.bias'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt= torch.load(Encoder_frozen_PT_weights)\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(ckpt):\n",
    "    new_ckpt={}\n",
    "    for key in ckpt.keys():\n",
    "        if \"lora\" in key:\n",
    "            new_key = key.replace(\"lora_vit.\",\"\")\n",
    "            new_ckpt[new_key] = ckpt[key]\n",
    "        else:\n",
    "            new_ckpt[key] = ckpt[key]\n",
    "            \n",
    "    return new_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CustomedUNETR:\n\tMissing key(s) in state_dict: \"vit.patch_embedding.position_embeddings\", \"vit.patch_embedding.patch_embeddings.weight\", \"vit.patch_embedding.patch_embeddings.bias\", \"vit.blocks.0.mlp.linear1.weight\", \"vit.blocks.0.mlp.linear1.bias\", \"vit.blocks.0.mlp.linear2.weight\", \"vit.blocks.0.mlp.linear2.bias\", \"vit.blocks.0.norm1.weight\", \"vit.blocks.0.norm1.bias\", \"vit.blocks.0.attn.out_proj.weight\", \"vit.blocks.0.attn.out_proj.bias\", \"vit.blocks.0.attn.proj_q.weight\", \"vit.blocks.0.attn.proj_k.weight\", \"vit.blocks.0.attn.proj_v.weight\", \"vit.blocks.0.norm2.weight\", \"vit.blocks.0.norm2.bias\", \"vit.blocks.1.mlp.linear1.weight\", \"vit.blocks.1.mlp.linear1.bias\", \"vit.blocks.1.mlp.linear2.weight\", \"vit.blocks.1.mlp.linear2.bias\", \"vit.blocks.1.norm1.weight\", \"vit.blocks.1.norm1.bias\", \"vit.blocks.1.attn.out_proj.weight\", \"vit.blocks.1.attn.out_proj.bias\", \"vit.blocks.1.attn.proj_q.weight\", \"vit.blocks.1.attn.proj_k.weight\", \"vit.blocks.1.attn.proj_v.weight\", \"vit.blocks.1.norm2.weight\", \"vit.blocks.1.norm2.bias\", \"vit.blocks.2.mlp.linear1.weight\", \"vit.blocks.2.mlp.linear1.bias\", \"vit.blocks.2.mlp.linear2.weight\", \"vit.blocks.2.mlp.linear2.bias\", \"vit.blocks.2.norm1.weight\", \"vit.blocks.2.norm1.bias\", \"vit.blocks.2.attn.out_proj.weight\", \"vit.blocks.2.attn.out_proj.bias\", \"vit.blocks.2.attn.proj_q.weight\", \"vit.blocks.2.attn.proj_k.weight\", \"vit.blocks.2.attn.proj_v.weight\", \"vit.blocks.2.norm2.weight\", \"vit.blocks.2.norm2.bias\", \"vit.blocks.3.mlp.linear1.weight\", \"vit.blocks.3.mlp.linear1.bias\", \"vit.blocks.3.mlp.linear2.weight\", \"vit.blocks.3.mlp.linear2.bias\", \"vit.blocks.3.norm1.weight\", \"vit.blocks.3.norm1.bias\", \"vit.blocks.3.attn.out_proj.weight\", \"vit.blocks.3.attn.out_proj.bias\", \"vit.blocks.3.attn.proj_q.weight\", \"vit.blocks.3.attn.proj_k.weight\", \"vit.blocks.3.attn.proj_v.weight\", \"vit.blocks.3.norm2.weight\", \"vit.blocks.3.norm2.bias\", \"vit.blocks.4.mlp.linear1.weight\", \"vit.blocks.4.mlp.linear1.bias\", \"vit.blocks.4.mlp.linear2.weight\", \"vit.blocks.4.mlp.linear2.bias\", \"vit.blocks.4.norm1.weight\", \"vit.blocks.4.norm1.bias\", \"vit.blocks.4.attn.out_proj.weight\", \"vit.blocks.4.attn.out_proj.bias\", \"vit.blocks.4.attn.proj_q.weight\", \"vit.blocks.4.attn.proj_k.weight\", \"vit.blocks.4.attn.proj_v.weight\", \"vit.blocks.4.norm2.weight\", \"vit.blocks.4.norm2.bias\", \"vit.blocks.5.mlp.linear1.weight\", \"vit.blocks.5.mlp.linear1.bias\", \"vit.blocks.5.mlp.linear2.weight\", \"vit.blocks.5.mlp.linear2.bias\", \"vit.blocks.5.norm1.weight\", \"vit.blocks.5.norm1.bias\", \"vit.blocks.5.attn.out_proj.weight\", \"vit.blocks.5.attn.out_proj.bias\", \"vit.blocks.5.attn.proj_q.weight\", \"vit.blocks.5.attn.proj_k.weight\", \"vit.blocks.5.attn.proj_v.weight\", \"vit.blocks.5.norm2.weight\", \"vit.blocks.5.norm2.bias\", \"vit.blocks.6.mlp.linear1.weight\", \"vit.blocks.6.mlp.linear1.bias\", \"vit.blocks.6.mlp.linear2.weight\", \"vit.blocks.6.mlp.linear2.bias\", \"vit.blocks.6.norm1.weight\", \"vit.blocks.6.norm1.bias\", \"vit.blocks.6.attn.out_proj.weight\", \"vit.blocks.6.attn.out_proj.bias\", \"vit.blocks.6.attn.proj_q.weight\", \"vit.blocks.6.attn.proj_k.weight\", \"vit.blocks.6.attn.proj_v.weight\", \"vit.blocks.6.norm2.weight\", \"vit.blocks.6.norm2.bias\", \"vit.blocks.7.mlp.linear1.weight\", \"vit.blocks.7.mlp.linear1.bias\", \"vit.blocks.7.mlp.linear2.weight\", \"vit.blocks.7.mlp.linear2.bias\", \"vit.blocks.7.norm1.weight\", \"vit.blocks.7.norm1.bias\", \"vit.blocks.7.attn.out_proj.weight\", \"vit.blocks.7.attn.out_proj.bias\", \"vit.blocks.7.attn.proj_q.weight\", \"vit.blocks.7.attn.proj_k.weight\", \"vit.blocks.7.attn.proj_v.weight\", \"vit.blocks.7.norm2.weight\", \"vit.blocks.7.norm2.bias\", \"vit.blocks.8.mlp.linear1.weight\", \"vit.blocks.8.mlp.linear1.bias\", \"vit.blocks.8.mlp.linear2.weight\", \"vit.blocks.8.mlp.linear2.bias\", \"vit.blocks.8.norm1.weight\", \"vit.blocks.8.norm1.bias\", \"vit.blocks.8.attn.out_proj.weight\", \"vit.blocks.8.attn.out_proj.bias\", \"vit.blocks.8.attn.proj_q.weight\", \"vit.blocks.8.attn.proj_k.weight\", \"vit.blocks.8.attn.proj_v.weight\", \"vit.blocks.8.norm2.weight\", \"vit.blocks.8.norm2.bias\", \"vit.blocks.9.mlp.linear1.weight\", \"vit.blocks.9.mlp.linear1.bias\", \"vit.blocks.9.mlp.linear2.weight\", \"vit.blocks.9.mlp.linear2.bias\", \"vit.blocks.9.norm1.weight\", \"vit.blocks.9.norm1.bias\", \"vit.blocks.9.attn.out_proj.weight\", \"vit.blocks.9.attn.out_proj.bias\", \"vit.blocks.9.attn.proj_q.weight\", \"vit.blocks.9.attn.proj_k.weight\", \"vit.blocks.9.attn.proj_v.weight\", \"vit.blocks.9.norm2.weight\", \"vit.blocks.9.norm2.bias\", \"vit.blocks.10.mlp.linear1.weight\", \"vit.blocks.10.mlp.linear1.bias\", \"vit.blocks.10.mlp.linear2.weight\", \"vit.blocks.10.mlp.linear2.bias\", \"vit.blocks.10.norm1.weight\", \"vit.blocks.10.norm1.bias\", \"vit.blocks.10.attn.out_proj.weight\", \"vit.blocks.10.attn.out_proj.bias\", \"vit.blocks.10.attn.proj_q.weight\", \"vit.blocks.10.attn.proj_k.weight\", \"vit.blocks.10.attn.proj_v.weight\", \"vit.blocks.10.norm2.weight\", \"vit.blocks.10.norm2.bias\", \"vit.blocks.11.mlp.linear1.weight\", \"vit.blocks.11.mlp.linear1.bias\", \"vit.blocks.11.mlp.linear2.weight\", \"vit.blocks.11.mlp.linear2.bias\", \"vit.blocks.11.norm1.weight\", \"vit.blocks.11.norm1.bias\", \"vit.blocks.11.attn.out_proj.weight\", \"vit.blocks.11.attn.out_proj.bias\", \"vit.blocks.11.attn.proj_q.weight\", \"vit.blocks.11.attn.proj_k.weight\", \"vit.blocks.11.attn.proj_v.weight\", \"vit.blocks.11.norm2.weight\", \"vit.blocks.11.norm2.bias\", \"vit.norm.weight\", \"vit.norm.bias\". \n\tUnexpected key(s) in state_dict: \"vit.lora_vit.patch_embedding.position_embeddings\", \"vit.lora_vit.patch_embedding.patch_embeddings.weight\", \"vit.lora_vit.patch_embedding.patch_embeddings.bias\", \"vit.lora_vit.blocks.0.mlp.linear1.weight\", \"vit.lora_vit.blocks.0.mlp.linear1.bias\", \"vit.lora_vit.blocks.0.mlp.linear2.weight\", \"vit.lora_vit.blocks.0.mlp.linear2.bias\", \"vit.lora_vit.blocks.0.norm1.weight\", \"vit.lora_vit.blocks.0.norm1.bias\", \"vit.lora_vit.blocks.0.attn.out_proj.weight\", \"vit.lora_vit.blocks.0.attn.out_proj.bias\", \"vit.lora_vit.blocks.0.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.0.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.0.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.0.attn.proj_k.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.0.norm2.weight\", \"vit.lora_vit.blocks.0.norm2.bias\", \"vit.lora_vit.blocks.1.mlp.linear1.weight\", \"vit.lora_vit.blocks.1.mlp.linear1.bias\", \"vit.lora_vit.blocks.1.mlp.linear2.weight\", \"vit.lora_vit.blocks.1.mlp.linear2.bias\", \"vit.lora_vit.blocks.1.norm1.weight\", \"vit.lora_vit.blocks.1.norm1.bias\", \"vit.lora_vit.blocks.1.attn.out_proj.weight\", \"vit.lora_vit.blocks.1.attn.out_proj.bias\", \"vit.lora_vit.blocks.1.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.1.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.1.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.1.attn.proj_k.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.1.norm2.weight\", \"vit.lora_vit.blocks.1.norm2.bias\", \"vit.lora_vit.blocks.2.mlp.linear1.weight\", \"vit.lora_vit.blocks.2.mlp.linear1.bias\", \"vit.lora_vit.blocks.2.mlp.linear2.weight\", \"vit.lora_vit.blocks.2.mlp.linear2.bias\", \"vit.lora_vit.blocks.2.norm1.weight\", \"vit.lora_vit.blocks.2.norm1.bias\", \"vit.lora_vit.blocks.2.attn.out_proj.weight\", \"vit.lora_vit.blocks.2.attn.out_proj.bias\", \"vit.lora_vit.blocks.2.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.2.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.2.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.2.attn.proj_k.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.2.norm2.weight\", \"vit.lora_vit.blocks.2.norm2.bias\", \"vit.lora_vit.blocks.3.mlp.linear1.weight\", \"vit.lora_vit.blocks.3.mlp.linear1.bias\", \"vit.lora_vit.blocks.3.mlp.linear2.weight\", \"vit.lora_vit.blocks.3.mlp.linear2.bias\", \"vit.lora_vit.blocks.3.norm1.weight\", \"vit.lora_vit.blocks.3.norm1.bias\", \"vit.lora_vit.blocks.3.attn.out_proj.weight\", \"vit.lora_vit.blocks.3.attn.out_proj.bias\", \"vit.lora_vit.blocks.3.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.3.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.3.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.3.attn.proj_k.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.3.norm2.weight\", \"vit.lora_vit.blocks.3.norm2.bias\", \"vit.lora_vit.blocks.4.mlp.linear1.weight\", \"vit.lora_vit.blocks.4.mlp.linear1.bias\", \"vit.lora_vit.blocks.4.mlp.linear2.weight\", \"vit.lora_vit.blocks.4.mlp.linear2.bias\", \"vit.lora_vit.blocks.4.norm1.weight\", \"vit.lora_vit.blocks.4.norm1.bias\", \"vit.lora_vit.blocks.4.attn.out_proj.weight\", \"vit.lora_vit.blocks.4.attn.out_proj.bias\", \"vit.lora_vit.blocks.4.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.4.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.4.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.4.attn.proj_k.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.4.norm2.weight\", \"vit.lora_vit.blocks.4.norm2.bias\", \"vit.lora_vit.blocks.5.mlp.linear1.weight\", \"vit.lora_vit.blocks.5.mlp.linear1.bias\", \"vit.lora_vit.blocks.5.mlp.linear2.weight\", \"vit.lora_vit.blocks.5.mlp.linear2.bias\", \"vit.lora_vit.blocks.5.norm1.weight\", \"vit.lora_vit.blocks.5.norm1.bias\", \"vit.lora_vit.blocks.5.attn.out_proj.weight\", \"vit.lora_vit.blocks.5.attn.out_proj.bias\", \"vit.lora_vit.blocks.5.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.5.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.5.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.5.attn.proj_k.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.5.norm2.weight\", \"vit.lora_vit.blocks.5.norm2.bias\", \"vit.lora_vit.blocks.6.mlp.linear1.weight\", \"vit.lora_vit.blocks.6.mlp.linear1.bias\", \"vit.lora_vit.blocks.6.mlp.linear2.weight\", \"vit.lora_vit.blocks.6.mlp.linear2.bias\", \"vit.lora_vit.blocks.6.norm1.weight\", \"vit.lora_vit.blocks.6.norm1.bias\", \"vit.lora_vit.blocks.6.attn.out_proj.weight\", \"vit.lora_vit.blocks.6.attn.out_proj.bias\", \"vit.lora_vit.blocks.6.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.6.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.6.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.6.attn.proj_k.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.6.norm2.weight\", \"vit.lora_vit.blocks.6.norm2.bias\", \"vit.lora_vit.blocks.7.mlp.linear1.weight\", \"vit.lora_vit.blocks.7.mlp.linear1.bias\", \"vit.lora_vit.blocks.7.mlp.linear2.weight\", \"vit.lora_vit.blocks.7.mlp.linear2.bias\", \"vit.lora_vit.blocks.7.norm1.weight\", \"vit.lora_vit.blocks.7.norm1.bias\", \"vit.lora_vit.blocks.7.attn.out_proj.weight\", \"vit.lora_vit.blocks.7.attn.out_proj.bias\", \"vit.lora_vit.blocks.7.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.7.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.7.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.7.attn.proj_k.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.7.norm2.weight\", \"vit.lora_vit.blocks.7.norm2.bias\", \"vit.lora_vit.blocks.8.mlp.linear1.weight\", \"vit.lora_vit.blocks.8.mlp.linear1.bias\", \"vit.lora_vit.blocks.8.mlp.linear2.weight\", \"vit.lora_vit.blocks.8.mlp.linear2.bias\", \"vit.lora_vit.blocks.8.norm1.weight\", \"vit.lora_vit.blocks.8.norm1.bias\", \"vit.lora_vit.blocks.8.attn.out_proj.weight\", \"vit.lora_vit.blocks.8.attn.out_proj.bias\", \"vit.lora_vit.blocks.8.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.8.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.8.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.8.attn.proj_k.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.8.norm2.weight\", \"vit.lora_vit.blocks.8.norm2.bias\", \"vit.lora_vit.blocks.9.mlp.linear1.weight\", \"vit.lora_vit.blocks.9.mlp.linear1.bias\", \"vit.lora_vit.blocks.9.mlp.linear2.weight\", \"vit.lora_vit.blocks.9.mlp.linear2.bias\", \"vit.lora_vit.blocks.9.norm1.weight\", \"vit.lora_vit.blocks.9.norm1.bias\", \"vit.lora_vit.blocks.9.attn.out_proj.weight\", \"vit.lora_vit.blocks.9.attn.out_proj.bias\", \"vit.lora_vit.blocks.9.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.9.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.9.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.9.attn.proj_k.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.9.norm2.weight\", \"vit.lora_vit.blocks.9.norm2.bias\", \"vit.lora_vit.blocks.10.mlp.linear1.weight\", \"vit.lora_vit.blocks.10.mlp.linear1.bias\", \"vit.lora_vit.blocks.10.mlp.linear2.weight\", \"vit.lora_vit.blocks.10.mlp.linear2.bias\", \"vit.lora_vit.blocks.10.norm1.weight\", \"vit.lora_vit.blocks.10.norm1.bias\", \"vit.lora_vit.blocks.10.attn.out_proj.weight\", \"vit.lora_vit.blocks.10.attn.out_proj.bias\", \"vit.lora_vit.blocks.10.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.10.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.10.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.10.attn.proj_k.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.10.norm2.weight\", \"vit.lora_vit.blocks.10.norm2.bias\", \"vit.lora_vit.blocks.11.mlp.linear1.weight\", \"vit.lora_vit.blocks.11.mlp.linear1.bias\", \"vit.lora_vit.blocks.11.mlp.linear2.weight\", \"vit.lora_vit.blocks.11.mlp.linear2.bias\", \"vit.lora_vit.blocks.11.norm1.weight\", \"vit.lora_vit.blocks.11.norm1.bias\", \"vit.lora_vit.blocks.11.attn.out_proj.weight\", \"vit.lora_vit.blocks.11.attn.out_proj.bias\", \"vit.lora_vit.blocks.11.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.11.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.11.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.11.attn.proj_k.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.11.norm2.weight\", \"vit.lora_vit.blocks.11.norm2.bias\", \"vit.lora_vit.norm.weight\", \"vit.lora_vit.norm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ckpt\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(Encoder_frozen_PT_weights)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# new_ckpt = load_weights(ckpt)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CustomedUNETR:\n\tMissing key(s) in state_dict: \"vit.patch_embedding.position_embeddings\", \"vit.patch_embedding.patch_embeddings.weight\", \"vit.patch_embedding.patch_embeddings.bias\", \"vit.blocks.0.mlp.linear1.weight\", \"vit.blocks.0.mlp.linear1.bias\", \"vit.blocks.0.mlp.linear2.weight\", \"vit.blocks.0.mlp.linear2.bias\", \"vit.blocks.0.norm1.weight\", \"vit.blocks.0.norm1.bias\", \"vit.blocks.0.attn.out_proj.weight\", \"vit.blocks.0.attn.out_proj.bias\", \"vit.blocks.0.attn.proj_q.weight\", \"vit.blocks.0.attn.proj_k.weight\", \"vit.blocks.0.attn.proj_v.weight\", \"vit.blocks.0.norm2.weight\", \"vit.blocks.0.norm2.bias\", \"vit.blocks.1.mlp.linear1.weight\", \"vit.blocks.1.mlp.linear1.bias\", \"vit.blocks.1.mlp.linear2.weight\", \"vit.blocks.1.mlp.linear2.bias\", \"vit.blocks.1.norm1.weight\", \"vit.blocks.1.norm1.bias\", \"vit.blocks.1.attn.out_proj.weight\", \"vit.blocks.1.attn.out_proj.bias\", \"vit.blocks.1.attn.proj_q.weight\", \"vit.blocks.1.attn.proj_k.weight\", \"vit.blocks.1.attn.proj_v.weight\", \"vit.blocks.1.norm2.weight\", \"vit.blocks.1.norm2.bias\", \"vit.blocks.2.mlp.linear1.weight\", \"vit.blocks.2.mlp.linear1.bias\", \"vit.blocks.2.mlp.linear2.weight\", \"vit.blocks.2.mlp.linear2.bias\", \"vit.blocks.2.norm1.weight\", \"vit.blocks.2.norm1.bias\", \"vit.blocks.2.attn.out_proj.weight\", \"vit.blocks.2.attn.out_proj.bias\", \"vit.blocks.2.attn.proj_q.weight\", \"vit.blocks.2.attn.proj_k.weight\", \"vit.blocks.2.attn.proj_v.weight\", \"vit.blocks.2.norm2.weight\", \"vit.blocks.2.norm2.bias\", \"vit.blocks.3.mlp.linear1.weight\", \"vit.blocks.3.mlp.linear1.bias\", \"vit.blocks.3.mlp.linear2.weight\", \"vit.blocks.3.mlp.linear2.bias\", \"vit.blocks.3.norm1.weight\", \"vit.blocks.3.norm1.bias\", \"vit.blocks.3.attn.out_proj.weight\", \"vit.blocks.3.attn.out_proj.bias\", \"vit.blocks.3.attn.proj_q.weight\", \"vit.blocks.3.attn.proj_k.weight\", \"vit.blocks.3.attn.proj_v.weight\", \"vit.blocks.3.norm2.weight\", \"vit.blocks.3.norm2.bias\", \"vit.blocks.4.mlp.linear1.weight\", \"vit.blocks.4.mlp.linear1.bias\", \"vit.blocks.4.mlp.linear2.weight\", \"vit.blocks.4.mlp.linear2.bias\", \"vit.blocks.4.norm1.weight\", \"vit.blocks.4.norm1.bias\", \"vit.blocks.4.attn.out_proj.weight\", \"vit.blocks.4.attn.out_proj.bias\", \"vit.blocks.4.attn.proj_q.weight\", \"vit.blocks.4.attn.proj_k.weight\", \"vit.blocks.4.attn.proj_v.weight\", \"vit.blocks.4.norm2.weight\", \"vit.blocks.4.norm2.bias\", \"vit.blocks.5.mlp.linear1.weight\", \"vit.blocks.5.mlp.linear1.bias\", \"vit.blocks.5.mlp.linear2.weight\", \"vit.blocks.5.mlp.linear2.bias\", \"vit.blocks.5.norm1.weight\", \"vit.blocks.5.norm1.bias\", \"vit.blocks.5.attn.out_proj.weight\", \"vit.blocks.5.attn.out_proj.bias\", \"vit.blocks.5.attn.proj_q.weight\", \"vit.blocks.5.attn.proj_k.weight\", \"vit.blocks.5.attn.proj_v.weight\", \"vit.blocks.5.norm2.weight\", \"vit.blocks.5.norm2.bias\", \"vit.blocks.6.mlp.linear1.weight\", \"vit.blocks.6.mlp.linear1.bias\", \"vit.blocks.6.mlp.linear2.weight\", \"vit.blocks.6.mlp.linear2.bias\", \"vit.blocks.6.norm1.weight\", \"vit.blocks.6.norm1.bias\", \"vit.blocks.6.attn.out_proj.weight\", \"vit.blocks.6.attn.out_proj.bias\", \"vit.blocks.6.attn.proj_q.weight\", \"vit.blocks.6.attn.proj_k.weight\", \"vit.blocks.6.attn.proj_v.weight\", \"vit.blocks.6.norm2.weight\", \"vit.blocks.6.norm2.bias\", \"vit.blocks.7.mlp.linear1.weight\", \"vit.blocks.7.mlp.linear1.bias\", \"vit.blocks.7.mlp.linear2.weight\", \"vit.blocks.7.mlp.linear2.bias\", \"vit.blocks.7.norm1.weight\", \"vit.blocks.7.norm1.bias\", \"vit.blocks.7.attn.out_proj.weight\", \"vit.blocks.7.attn.out_proj.bias\", \"vit.blocks.7.attn.proj_q.weight\", \"vit.blocks.7.attn.proj_k.weight\", \"vit.blocks.7.attn.proj_v.weight\", \"vit.blocks.7.norm2.weight\", \"vit.blocks.7.norm2.bias\", \"vit.blocks.8.mlp.linear1.weight\", \"vit.blocks.8.mlp.linear1.bias\", \"vit.blocks.8.mlp.linear2.weight\", \"vit.blocks.8.mlp.linear2.bias\", \"vit.blocks.8.norm1.weight\", \"vit.blocks.8.norm1.bias\", \"vit.blocks.8.attn.out_proj.weight\", \"vit.blocks.8.attn.out_proj.bias\", \"vit.blocks.8.attn.proj_q.weight\", \"vit.blocks.8.attn.proj_k.weight\", \"vit.blocks.8.attn.proj_v.weight\", \"vit.blocks.8.norm2.weight\", \"vit.blocks.8.norm2.bias\", \"vit.blocks.9.mlp.linear1.weight\", \"vit.blocks.9.mlp.linear1.bias\", \"vit.blocks.9.mlp.linear2.weight\", \"vit.blocks.9.mlp.linear2.bias\", \"vit.blocks.9.norm1.weight\", \"vit.blocks.9.norm1.bias\", \"vit.blocks.9.attn.out_proj.weight\", \"vit.blocks.9.attn.out_proj.bias\", \"vit.blocks.9.attn.proj_q.weight\", \"vit.blocks.9.attn.proj_k.weight\", \"vit.blocks.9.attn.proj_v.weight\", \"vit.blocks.9.norm2.weight\", \"vit.blocks.9.norm2.bias\", \"vit.blocks.10.mlp.linear1.weight\", \"vit.blocks.10.mlp.linear1.bias\", \"vit.blocks.10.mlp.linear2.weight\", \"vit.blocks.10.mlp.linear2.bias\", \"vit.blocks.10.norm1.weight\", \"vit.blocks.10.norm1.bias\", \"vit.blocks.10.attn.out_proj.weight\", \"vit.blocks.10.attn.out_proj.bias\", \"vit.blocks.10.attn.proj_q.weight\", \"vit.blocks.10.attn.proj_k.weight\", \"vit.blocks.10.attn.proj_v.weight\", \"vit.blocks.10.norm2.weight\", \"vit.blocks.10.norm2.bias\", \"vit.blocks.11.mlp.linear1.weight\", \"vit.blocks.11.mlp.linear1.bias\", \"vit.blocks.11.mlp.linear2.weight\", \"vit.blocks.11.mlp.linear2.bias\", \"vit.blocks.11.norm1.weight\", \"vit.blocks.11.norm1.bias\", \"vit.blocks.11.attn.out_proj.weight\", \"vit.blocks.11.attn.out_proj.bias\", \"vit.blocks.11.attn.proj_q.weight\", \"vit.blocks.11.attn.proj_k.weight\", \"vit.blocks.11.attn.proj_v.weight\", \"vit.blocks.11.norm2.weight\", \"vit.blocks.11.norm2.bias\", \"vit.norm.weight\", \"vit.norm.bias\". \n\tUnexpected key(s) in state_dict: \"vit.lora_vit.patch_embedding.position_embeddings\", \"vit.lora_vit.patch_embedding.patch_embeddings.weight\", \"vit.lora_vit.patch_embedding.patch_embeddings.bias\", \"vit.lora_vit.blocks.0.mlp.linear1.weight\", \"vit.lora_vit.blocks.0.mlp.linear1.bias\", \"vit.lora_vit.blocks.0.mlp.linear2.weight\", \"vit.lora_vit.blocks.0.mlp.linear2.bias\", \"vit.lora_vit.blocks.0.norm1.weight\", \"vit.lora_vit.blocks.0.norm1.bias\", \"vit.lora_vit.blocks.0.attn.out_proj.weight\", \"vit.lora_vit.blocks.0.attn.out_proj.bias\", \"vit.lora_vit.blocks.0.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.0.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.0.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.0.attn.proj_k.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.0.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.0.norm2.weight\", \"vit.lora_vit.blocks.0.norm2.bias\", \"vit.lora_vit.blocks.1.mlp.linear1.weight\", \"vit.lora_vit.blocks.1.mlp.linear1.bias\", \"vit.lora_vit.blocks.1.mlp.linear2.weight\", \"vit.lora_vit.blocks.1.mlp.linear2.bias\", \"vit.lora_vit.blocks.1.norm1.weight\", \"vit.lora_vit.blocks.1.norm1.bias\", \"vit.lora_vit.blocks.1.attn.out_proj.weight\", \"vit.lora_vit.blocks.1.attn.out_proj.bias\", \"vit.lora_vit.blocks.1.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.1.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.1.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.1.attn.proj_k.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.1.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.1.norm2.weight\", \"vit.lora_vit.blocks.1.norm2.bias\", \"vit.lora_vit.blocks.2.mlp.linear1.weight\", \"vit.lora_vit.blocks.2.mlp.linear1.bias\", \"vit.lora_vit.blocks.2.mlp.linear2.weight\", \"vit.lora_vit.blocks.2.mlp.linear2.bias\", \"vit.lora_vit.blocks.2.norm1.weight\", \"vit.lora_vit.blocks.2.norm1.bias\", \"vit.lora_vit.blocks.2.attn.out_proj.weight\", \"vit.lora_vit.blocks.2.attn.out_proj.bias\", \"vit.lora_vit.blocks.2.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.2.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.2.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.2.attn.proj_k.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.2.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.2.norm2.weight\", \"vit.lora_vit.blocks.2.norm2.bias\", \"vit.lora_vit.blocks.3.mlp.linear1.weight\", \"vit.lora_vit.blocks.3.mlp.linear1.bias\", \"vit.lora_vit.blocks.3.mlp.linear2.weight\", \"vit.lora_vit.blocks.3.mlp.linear2.bias\", \"vit.lora_vit.blocks.3.norm1.weight\", \"vit.lora_vit.blocks.3.norm1.bias\", \"vit.lora_vit.blocks.3.attn.out_proj.weight\", \"vit.lora_vit.blocks.3.attn.out_proj.bias\", \"vit.lora_vit.blocks.3.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.3.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.3.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.3.attn.proj_k.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.3.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.3.norm2.weight\", \"vit.lora_vit.blocks.3.norm2.bias\", \"vit.lora_vit.blocks.4.mlp.linear1.weight\", \"vit.lora_vit.blocks.4.mlp.linear1.bias\", \"vit.lora_vit.blocks.4.mlp.linear2.weight\", \"vit.lora_vit.blocks.4.mlp.linear2.bias\", \"vit.lora_vit.blocks.4.norm1.weight\", \"vit.lora_vit.blocks.4.norm1.bias\", \"vit.lora_vit.blocks.4.attn.out_proj.weight\", \"vit.lora_vit.blocks.4.attn.out_proj.bias\", \"vit.lora_vit.blocks.4.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.4.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.4.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.4.attn.proj_k.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.4.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.4.norm2.weight\", \"vit.lora_vit.blocks.4.norm2.bias\", \"vit.lora_vit.blocks.5.mlp.linear1.weight\", \"vit.lora_vit.blocks.5.mlp.linear1.bias\", \"vit.lora_vit.blocks.5.mlp.linear2.weight\", \"vit.lora_vit.blocks.5.mlp.linear2.bias\", \"vit.lora_vit.blocks.5.norm1.weight\", \"vit.lora_vit.blocks.5.norm1.bias\", \"vit.lora_vit.blocks.5.attn.out_proj.weight\", \"vit.lora_vit.blocks.5.attn.out_proj.bias\", \"vit.lora_vit.blocks.5.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.5.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.5.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.5.attn.proj_k.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.5.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.5.norm2.weight\", \"vit.lora_vit.blocks.5.norm2.bias\", \"vit.lora_vit.blocks.6.mlp.linear1.weight\", \"vit.lora_vit.blocks.6.mlp.linear1.bias\", \"vit.lora_vit.blocks.6.mlp.linear2.weight\", \"vit.lora_vit.blocks.6.mlp.linear2.bias\", \"vit.lora_vit.blocks.6.norm1.weight\", \"vit.lora_vit.blocks.6.norm1.bias\", \"vit.lora_vit.blocks.6.attn.out_proj.weight\", \"vit.lora_vit.blocks.6.attn.out_proj.bias\", \"vit.lora_vit.blocks.6.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.6.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.6.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.6.attn.proj_k.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.6.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.6.norm2.weight\", \"vit.lora_vit.blocks.6.norm2.bias\", \"vit.lora_vit.blocks.7.mlp.linear1.weight\", \"vit.lora_vit.blocks.7.mlp.linear1.bias\", \"vit.lora_vit.blocks.7.mlp.linear2.weight\", \"vit.lora_vit.blocks.7.mlp.linear2.bias\", \"vit.lora_vit.blocks.7.norm1.weight\", \"vit.lora_vit.blocks.7.norm1.bias\", \"vit.lora_vit.blocks.7.attn.out_proj.weight\", \"vit.lora_vit.blocks.7.attn.out_proj.bias\", \"vit.lora_vit.blocks.7.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.7.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.7.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.7.attn.proj_k.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.7.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.7.norm2.weight\", \"vit.lora_vit.blocks.7.norm2.bias\", \"vit.lora_vit.blocks.8.mlp.linear1.weight\", \"vit.lora_vit.blocks.8.mlp.linear1.bias\", \"vit.lora_vit.blocks.8.mlp.linear2.weight\", \"vit.lora_vit.blocks.8.mlp.linear2.bias\", \"vit.lora_vit.blocks.8.norm1.weight\", \"vit.lora_vit.blocks.8.norm1.bias\", \"vit.lora_vit.blocks.8.attn.out_proj.weight\", \"vit.lora_vit.blocks.8.attn.out_proj.bias\", \"vit.lora_vit.blocks.8.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.8.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.8.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.8.attn.proj_k.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.8.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.8.norm2.weight\", \"vit.lora_vit.blocks.8.norm2.bias\", \"vit.lora_vit.blocks.9.mlp.linear1.weight\", \"vit.lora_vit.blocks.9.mlp.linear1.bias\", \"vit.lora_vit.blocks.9.mlp.linear2.weight\", \"vit.lora_vit.blocks.9.mlp.linear2.bias\", \"vit.lora_vit.blocks.9.norm1.weight\", \"vit.lora_vit.blocks.9.norm1.bias\", \"vit.lora_vit.blocks.9.attn.out_proj.weight\", \"vit.lora_vit.blocks.9.attn.out_proj.bias\", \"vit.lora_vit.blocks.9.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.9.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.9.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.9.attn.proj_k.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.9.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.9.norm2.weight\", \"vit.lora_vit.blocks.9.norm2.bias\", \"vit.lora_vit.blocks.10.mlp.linear1.weight\", \"vit.lora_vit.blocks.10.mlp.linear1.bias\", \"vit.lora_vit.blocks.10.mlp.linear2.weight\", \"vit.lora_vit.blocks.10.mlp.linear2.bias\", \"vit.lora_vit.blocks.10.norm1.weight\", \"vit.lora_vit.blocks.10.norm1.bias\", \"vit.lora_vit.blocks.10.attn.out_proj.weight\", \"vit.lora_vit.blocks.10.attn.out_proj.bias\", \"vit.lora_vit.blocks.10.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.10.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.10.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.10.attn.proj_k.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.10.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.10.norm2.weight\", \"vit.lora_vit.blocks.10.norm2.bias\", \"vit.lora_vit.blocks.11.mlp.linear1.weight\", \"vit.lora_vit.blocks.11.mlp.linear1.bias\", \"vit.lora_vit.blocks.11.mlp.linear2.weight\", \"vit.lora_vit.blocks.11.mlp.linear2.bias\", \"vit.lora_vit.blocks.11.norm1.weight\", \"vit.lora_vit.blocks.11.norm1.bias\", \"vit.lora_vit.blocks.11.attn.out_proj.weight\", \"vit.lora_vit.blocks.11.attn.out_proj.bias\", \"vit.lora_vit.blocks.11.attn.proj_q.w.weight\", \"vit.lora_vit.blocks.11.attn.proj_q.w_a.weight\", \"vit.lora_vit.blocks.11.attn.proj_q.w_b.weight\", \"vit.lora_vit.blocks.11.attn.proj_k.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w_a.weight\", \"vit.lora_vit.blocks.11.attn.proj_v.w_b.weight\", \"vit.lora_vit.blocks.11.norm2.weight\", \"vit.lora_vit.blocks.11.norm2.bias\", \"vit.lora_vit.norm.weight\", \"vit.lora_vit.norm.bias\". "
     ]
    }
   ],
   "source": [
    "ckpt= torch.load(Encoder_frozen_PT_weights)\n",
    "# new_ckpt = load_weights(ckpt)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "Encoder_frozen_PT_weights = '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf-decoderfrozen/m2-withpet-intheskipconnection-firsthalf-decoderfrozen.pth'\n",
    "msg = model.load_state_dict(torch.load(Encoder_frozen_PT_weights), strict=False)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1799742331.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    padding = [0, 0, 0]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#def sliding_window_inference_fix(inputs, roi_size, sw_batch_size, model):#\n",
    "    # Calculate the padding required to make the input size a multiple of the roi_size\n",
    "    padding = [0, 0, 0]\n",
    "    for i in range(3):\n",
    "        if inputs.shape[i + 2] % roi_size[i] != 0:\n",
    "            padding[i] = roi_size[i] - (inputs.shape[i + 2] % roi_size[i])\n",
    "\n",
    "    # Pad the inputs if necessary\n",
    "    if sum(padding) > 0:\n",
    "        pad_fn = nn.ConstantPad3d(padding, 0)\n",
    "        inputs = pad_fn(inputs)\n",
    "\n",
    "# Perform sliding window inference\n",
    "    outputs = []\n",
    "    for i in range(0, inputs.shape[2] - roi_size[0] + 1, roi_size[0]):\n",
    "        for j in range(0, inputs.shape[3] - roi_size[1] + 1, roi_size[1]):\n",
    "            for k in range(0, inputs.shape[4] - roi_size[2] + 1, roi_size[2]):\n",
    "                input_patch = inputs[:, :, i:i+roi_size[0], j:j+roi_size[1], k:k+roi_size[2]]\n",
    "                output_patch = model(input_patch)\n",
    "                outputs.append(output_patch)\n",
    "\n",
    "    # Remove padding from the outputs\n",
    "    if sum(padding) > 0:\n",
    "        outputs = outputs[:-(padding[0] * padding[1] * padding[2])]\n",
    "\n",
    "    return torch.cat(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved at: /home/nada.saadi/CTPET/hecktor2022_cropped/testing_ct_saved_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 6, 6, 6, 768]' is invalid for input of size 331776",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 101\u001b[0m\n\u001b[1;32m     97\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel weights saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m \u001b[43mtesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 79\u001b[0m, in \u001b[0;36mtesting\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[1;32m     77\u001b[0m     test_inputs, test_labels \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(), batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 79\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Convert outputs and labels to one-hot format for DiceMetric calculation\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m [AsDiscrete(argmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(test_outputs)]\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/inferers/utils.py:229\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, progress, roi_weight_map, process_fn, buffer_steps, buffer_dim, with_coord, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     seg_prob_out \u001b[38;5;241m=\u001b[39m predictor(win_data, unravel_slice, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# batched patch\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     seg_prob_out \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwin_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# batched patch\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# convert seg_prob_out to tuple seg_tuple, this does not allocate new memory.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m dict_keys, seg_tuple \u001b[38;5;241m=\u001b[39m _flatten_struct(seg_prob_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CTPET/hecktor2022_cropped/unetr.py:409\u001b[0m, in \u001b[0;36mCustomedUNETR.forward\u001b[0;34m(self, x_in, mode)\u001b[0m\n\u001b[1;32m    406\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m x2[:, ::\u001b[38;5;241m2\u001b[39m, :]  \u001b[38;5;66;03m# mixture both ct and pet alternating\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m#print(f\"After slicing: {x2.shape}\")\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m enc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    411\u001b[0m x3 \u001b[38;5;241m=\u001b[39m hidden_states_out[\u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/CTPET/hecktor2022_cropped/unetr.py:313\u001b[0m, in \u001b[0;36mCustomedUNETR.proj_feat\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m new_view \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)] \u001b[38;5;241m+\u001b[39m proj_view_shape\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# In proj_feat:\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# print(f\"Before reshaping x : {x.shape}\")\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_view\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# print(f\"After reshaping x: {x.shape}\")\u001b[39;00m\n\u001b[1;32m    315\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_axes)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 6, 6, 6, 768]' is invalid for input of size 331776"
     ]
    }
   ],
   "source": [
    "from monai.transforms import apply_transform\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained weights\n",
    "# Encoder_frozen_PT_weights ='/home/nada.saadi/CTPET/hecktor2022_cropped/module2-cttokens/m2-cttokens.pth'\n",
    "# #Encoder_frozen_PT_weights = '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf/m2-withpet-intheskipconnection-firsthalf.pth'\n",
    "# #Encoder_frozen_PT_weights = '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf-decoderfrozen/m2-withpet-intheskipconnection-firsthalf-decoderfrozen.pth'\n",
    "# msg = model.load_state_dict(torch.load(Encoder_frozen_PT_weights), strict=False)\n",
    "# print(msg)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "# Encoder_frozen_PT_weights = '/home/nada.saadi/CTPET/hecktor2022_cropped/Experiments with Lora/MDA-CTPT-LORA-ENCODERFROZEN/mda-ctpt-loraencoderfrozen.pth'\n",
    "\n",
    "# # Load the pre-trained weights only for the matching layers\n",
    "\n",
    "# Load the pre-trained weights only for the matching layers\n",
    "# state_dict = torch.load(Encoder_frozen_PT_weights)\n",
    "# model_dict = model.state_dict()\n",
    "# matched_state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "# # Fix the size mismatch for encoder1.layer.conv1.conv.weight and encoder1.layer.conv3.conv.bias\n",
    "# matched_state_dict['encoder1.layer.conv1.conv.weight'] = matched_state_dict['encoder1.layer.conv1.conv.weight'][:, :1, :, :, :]\n",
    "# matched_state_dict['encoder1.layer.conv3.conv.weight'] = matched_state_dict['encoder1.layer.conv3.conv.weight'][:, :1, :, :, :]  \n",
    "\n",
    "# model_dict.update(matched_state_dict)\n",
    "# model.load_state_dict(model_dict)\n",
    "\n",
    "# Assume `test_ct_only` is your test CT only dataset loaded from a JSON or other sources\n",
    "# For demonstration, let's say `test_ct_only` is available as a list of dictionaries\n",
    "# Each dictionary contains paths to the 'ct', 'pt', and 'seg' for each test sample\n",
    "\n",
    "# Assume `val_transforms` is already defined and includes all necessary preprocessing steps\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     dataset=Dataset(data=modified_valid_data, transform=val_transforms),\n",
    "#     batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "#     shuffle=False,\n",
    "#     num_workers=4\n",
    "# )\n",
    "import io\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "ct_data='/home/nada.saadi/CTPET/hecktor2022_cropped/test_ct_only_mda.json'\n",
    "with open(ct_data, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=Dataset(data=test_data, transform=val_transforms),\n",
    "    batch_size=1,  # Batch size for testing can be 1 since no backpropagation is required\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=3)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=3)\n",
    "\n",
    "# Dice metric for evaluation\n",
    "dice_metric_fn = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "dice_metric_batch_fn = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "\n",
    "ctweights= '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf-decoderfrozen/m2-withpet-intheskipconnection-firsthalf-decoderfrozen.pth'\n",
    "model.load_state_dict(torch.load(ctweights), strict=False)\n",
    "\n",
    "def testing():\n",
    "    model.eval()\n",
    "    dice_metric_fn.reset()\n",
    "    dice_metric_batch_fn.reset()\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(test_loader):\n",
    "            test_inputs, test_labels = batch_data[\"ct\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "            \n",
    "            test_outputs = sliding_window_inference(test_inputs, (96, 96, 96), 4, model)\n",
    "            \n",
    "            # Convert outputs and labels to one-hot format for DiceMetric calculation\n",
    "            test_outputs = [AsDiscrete(argmax=True, to_onehot=3)(i) for i in decollate_batch(test_outputs)]\n",
    "            test_labels = [AsDiscrete(to_onehot=3)(i) for i in decollate_batch(test_labels)]\n",
    "\n",
    "            dice_metric_fn(y_pred=test_outputs, y=test_labels)\n",
    "            dice_metric_batch_fn(y_pred=test_outputs, y=test_labels)\n",
    "\n",
    "    mean_dice_test = dice_metric_fn.aggregate().item()\n",
    "    metric_batch_test = dice_metric_batch_fn.aggregate()\n",
    "    metric_tumor = metric_batch_test[0].item()\n",
    "    metric_lymph = metric_batch_test[1].item()\n",
    "\n",
    "    print(f\"Testing - Avg Dice: {mean_dice_test:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "    return mean_dice_test, metric_tumor, metric_lymph\n",
    "    # Save the weights\n",
    "save_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/testing_ct_saved_weights.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model weights saved at: {save_path}\")\n",
    "\n",
    "\n",
    "testing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.inferers import sliding_window_inference\n",
    "# from monai.transforms import AsDiscrete\n",
    "# from monai.metrics import DiceMetric\n",
    "# from monai.data import DataLoader, Dataset, decollate_batch\n",
    "# from tqdm import tqdm\n",
    "# import json\n",
    "\n",
    "\n",
    "# # Load the pre-trained weights\n",
    "# pretrained_weights_path = '/home/nada.saadi/CTPET/hecktor2022_cropped/module2-with-pet-skipconnection-firsthalf/m2-withpet-intheskipconnection-firsthalf.pth'\n",
    "# model.load_state_dict(torch.load(pretrained_weights_path), strict=True)\n",
    "\n",
    "# # Assume `valid_data` is your validation dataset loaded from a JSON or other sources\n",
    "# # For demonstration, let's say `valid_data` is available as a list of dictionaries\n",
    "# # Each dictionary contains paths to the 'ct', 'pt', and 'seg' for each validation sample\n",
    "\n",
    "# # Assume `val_transforms` is already defined and includes all necessary preprocessing steps\n",
    "# test_ct_only = '/home/nada.saadi/CTPET/hecktor2022_cropped/test_ct_only_mda.json'\n",
    "\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     dataset=Dataset(data=test_ct_only, transform=val_transforms),\n",
    "#     batch_size=1,  # Batch size for validation can be 1 since no backpropagation is required\n",
    "#     shuffle=False,\n",
    "#     num_workers=4\n",
    "# )\n",
    "\n",
    "# # Dice metric for evaluation\n",
    "# dice_metric_fn = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "# dice_metric_batch_fn = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "\n",
    "# def validation():\n",
    "#     model.eval()\n",
    "#     dice_metric_fn.reset()\n",
    "#     dice_metric_batch_fn.reset()\n",
    "#     with torch.no_grad():\n",
    "#         for batch_data in tqdm(val_loader,fold=0):\n",
    "#             val_inputs, val_labels = batch_data[\"ct\"].cuda(), batch_data[\"seg\"].cuda()\n",
    "#             val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model)\n",
    "            \n",
    "#             # Convert outputs and labels to one-hot format for DiceMetric calculation\n",
    "#             val_outputs = [AsDiscrete(argmax=True, to_onehot=3)(i) for i in decollate_batch(val_outputs)]\n",
    "#             val_labels = [AsDiscrete(to_onehot=3)(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "#             dice_metric_fn(y_pred=val_outputs, y=val_labels)\n",
    "#             dice_metric_batch_fn(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "#     mean_dice_val = dice_metric_fn.aggregate().item()\n",
    "#     metric_batch_val = dice_metric_batch_fn.aggregate()\n",
    "#     metric_tumor = metric_batch_val[0].item()\n",
    "#     metric_lymph = metric_batch_val[1].item()\n",
    "\n",
    "#     print(f\"Validation - Avg Dice: {mean_dice_val:.4f}, Tumor Dice: {metric_tumor:.4f}, Lymph Dice: {metric_lymph:.4f}\")\n",
    "\n",
    "# # Run validation\n",
    "# validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Check the format of valid_data\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m check_data_format(\u001b[43mvalid_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "def check_data_format(data):\n",
    "    if not isinstance(data, list):\n",
    "        print(\"Data is not a list.\")\n",
    "        return False\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        if not isinstance(item, dict):\n",
    "            print(f\"Item at index {i} is not a dictionary.\")\n",
    "            return False\n",
    "        if len(item) != 2:\n",
    "            print(f\"Dictionary at index {i} does not have exactly two key-value pairs.\")\n",
    "            return False\n",
    "\n",
    "    print(\"Data format is correct.\")\n",
    "    return True\n",
    "\n",
    "# Check the format of valid_data\n",
    "check_data_format(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format is correct.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_modified_data(data):\n",
    "    modified_data = []\n",
    "    for item in data:\n",
    "        modified_item = {key: item[key] for key in ['ct', 'seg']}\n",
    "        modified_data.append(modified_item)\n",
    "    return modified_data\n",
    "\n",
    "# Create a modified version of valid_data\n",
    "modified_valid_data = create_modified_data(valid_data)\n",
    "\n",
    "# Check the format of modified_valid_data\n",
    "check_data_format(modified_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001', 'ct': metatensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5511, 0.5957, 0.4978,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5551, 0.6059, 0.5246,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5240, 0.5877, 0.5301,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4199, 0.4112, 0.3917,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4182, 0.3949, 0.3633,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4093, 0.3834, 0.3533,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5441, 0.4395, 0.1617,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5692, 0.4829, 0.2213,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5822, 0.5262, 0.2913,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3157, 0.3366, 0.3448,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3887, 0.3823, 0.3650,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4220, 0.3961, 0.3639,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2916, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3476, 0.0445, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3865, 0.1191, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2154, 0.2535, 0.2815,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2493, 0.2761, 0.2925,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2951, 0.3157, 0.3244,  ..., 0.0000, 0.0000, 0.0000]]]]), 'seg': metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), 'fold': 0}\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import apply_transform\n",
    "test_sample = {'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_gt.nii.gz', 'fold': 0}\n",
    "transformed_sample = apply_transform(val_transforms, test_sample)\n",
    "print(transformed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-001/MDA-001_gt.nii.gz', 'fold': 0}, {'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007/MDA-007_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-007/MDA-007_gt.nii.gz', 'fold': 0}, {'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015/MDA-015_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-015/MDA-015_gt.nii.gz', 'fold': 0}, {'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018/MDA-018_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-018/MDA-018_gt.nii.gz', 'fold': 0}, {'id': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028', 'ct': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028/MDA-028_ct.nii.gz', 'seg': '/home/nada.saadi/MIS-FM/hecktor2022_cropped/data/MDA-028/MDA-028_gt.nii.gz', 'fold': 0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_ct_only = '/home/nada.saadi/CTPET/hecktor2022_cropped/test_ct_only_mda.json'\n",
    "\n",
    "with open(test_ct_only) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "first_5_elements = data[:5]\n",
    "print(first_5_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.compose.Compose object at 0x7fbf900077f0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/io/dictionary.py:160\u001b[0m, in \u001b[0;36mLoadImaged.__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    KeyError: When not ``self.overwriting`` and key already exists in ``data``.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, meta_key, meta_key_postfix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_iterator(d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_key_postfix):\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[1;32m    334\u001b[0m _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[0;32m--> 335\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[0;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[1;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[0;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fc1b81b4eb0>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Manually iterate over the dataset and apply transforms\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n\u001b[0;32m----> 9\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# This should not raise an error if everything is correct\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sample\u001b[38;5;241m.\u001b[39mkeys())  \u001b[38;5;66;03m# Should print dict keys including 'ct' and 'seg'\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:98\u001b[0m, in \u001b[0;36mDataset._transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mFetch single data item from `self.data`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m data_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data_i\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.compose.Compose object at 0x7fbf900077f0>"
     ]
    }
   ],
   "source": [
    "from monai.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming test_ct_only is a list of dictionaries as shown in your JSON snippet\n",
    "dataset = Dataset(data=test_ct_only, transform=val_transforms)\n",
    "\n",
    "# Manually iterate over the dataset and apply transforms\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    sample = dataset[i]  # This should not raise an error if everything is correct\n",
    "    print(sample.keys())  # Should print dict keys including 'ct' and 'seg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.compose.Compose object at 0x7fbf900077f0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/io/dictionary.py:160\u001b[0m, in \u001b[0;36mLoadImaged.__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    KeyError: When not ``self.overwriting`` and key already exists in ``data``.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, meta_key, meta_key_postfix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_iterator(d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_key_postfix):\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[1;32m    334\u001b[0m _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[0;32m--> 335\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[0;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[1;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[0;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fc1b81b4eb0>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:98\u001b[0m, in \u001b[0;36mDataset._transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mFetch single data item from `self.data`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m data_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data_i\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.compose.Compose object at 0x7fbf900077f0>"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.compose.Compose object at 0x7fc0e961c070>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/io/dictionary.py:160\u001b[0m, in \u001b[0;36mLoadImaged.__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    KeyError: When not ``self.overwriting`` and key already exists in ``data``.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, meta_key, meta_key_postfix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_iterator(d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_key_postfix):\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[1;32m    334\u001b[0m _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[0;32m--> 335\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[0;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[1;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[0;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fc0e961c6a0>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m simple_transforms \u001b[38;5;241m=\u001b[39m Compose([LoadImaged(keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m\"\u001b[39m], ensure_channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m      2\u001b[0m simple_dataset \u001b[38;5;241m=\u001b[39m Dataset(data\u001b[38;5;241m=\u001b[39mtest_ct_only, transform\u001b[38;5;241m=\u001b[39msimple_transforms)\n\u001b[0;32m----> 3\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43msimple_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample)\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/data/dataset.py:98\u001b[0m, in \u001b[0;36mDataset._transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mFetch single data item from `self.data`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m data_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data_i\n",
      "File \u001b[0;32m~/miniconda3/envs/clam/lib/python3.8/site-packages/monai/transforms/transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.compose.Compose object at 0x7fc0e961c070>"
     ]
    }
   ],
   "source": [
    "simple_transforms = Compose([LoadImaged(keys=[\"ct\", \"seg\"], ensure_channel_first=True)])\n",
    "simple_dataset = Dataset(data=test_ct_only, transform=simple_transforms)\n",
    "sample = simple_dataset[0]\n",
    "print(sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
